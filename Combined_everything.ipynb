{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
       "    help : 'run all cells',\n",
       "    help_index : 'zz',\n",
       "    handler : function (event) {\n",
       "        IPython.notebook.execute_all_cells();\n",
       "        return false;\n",
       "    }}\n",
       ");\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "Jupyter.keyboard_manager.command_shortcuts.add_shortcut('r', {\n",
    "    help : 'run all cells',\n",
    "    help_index : 'zz',\n",
    "    handler : function (event) {\n",
    "        IPython.notebook.execute_all_cells();\n",
    "        return false;\n",
    "    }}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from loess.Loess import Loess\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import loess\n",
    "import random\n",
    "import os\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Virus tramission temperarture range(in Fahrenheit)\n",
    "a=60\n",
    "b=95\n",
    "# Converting Fahrenheit to Kelvin\n",
    "a=(a-32)*5/9 + 273\n",
    "b=(b-32)*5/9 + 273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file with WNV data\n",
    "wnv_file_path= \"/Users/sparshagarwal/Downloads/WMV_data/Arbovirus_risk_modeling_US/WNV_human_cases/WNV_NI_NNI_1999to2015_prevalence_incidence_final_20180530.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "months=[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "years=range(1999, 2016)\n",
    "summer_mon=[\"05\", \"06\", \"07\", \"08\", \"09\"]   #Summer months for WNV transmission\n",
    "months_desc={\"01\": \"Jan\", \"02\": \"Feb\", \"03\": \"Mar\", \"04\": \"Apr\", \"05\": \"May\", \"06\": \"Jun\", \"07\" :\"Jul\", \"08\": \"Aug\", \"09\": \"Sep\", \"10\": \"Oct\", \"11\" : \"Nov\", \"12\" : \"Dec\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining socio-economic zones/regions\n",
    "socio_regions={\"WA\":1, \"OR\":1, \"CA\":1, \"MT\":2, \"ID\":2, \"WY\":2, \"NV\":2, \"UT\":2, \"CO\":2, \"AZ\":2, \"NM\":2,\"ND\":3, \"SD\":3, \"MN\":3, \"NE\":3, \"IA\":3,\"KS\":3, \"MO\":3, \"OK\":4 , \"TX\":4, \"AR\":4, \"LA\":4, \"WI\":5, \"MI\":5, \"IL\":5, \"IN\":5, \"OH\":5, \"KY\":6, \"TN\":6, \"AL\":6, \"MS\":6, \"WV\":7, \"VA\":7, \"NC\":7, \"SC\":7, \"DC\":7, \"MD\":7, \"DE\":7, \"GA\":7, \"FL\":7, \"PA\":8, \"NJ\":8, \"NY\":8, \"MA\":9, \"CT\":9, \"NH\":9, \"VT\":9, \"ME\":9, \"RI\":9}\n",
    "socio_key={1:\"Pacific\", 2:\"Mountain\", 3:\"West North Central\", 4: \"West South Central\", 5: \"East North Central\", 6: \"East South Central\", 7: \"South Atlantic\", 8: \"Middle Atlantic\", 9: \"New England\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining climatic zones/regions\n",
    "weather_regions={\"WA\":1, \"OR\":1, \"ID\":1, \"NV\":2, \"CA\":2, \"MT\":3, \"WY\":3,\"ND\":3, \"SD\":3, \"NE\":3,\"UT\":4, \"CO\":4, \"AZ\":4, \"NM\":4, \"MN\":5,\"WI\":5, \"MI\":5, \"IA\":5,\"KS\":6, \"OK\":6 , \"TX\":6, \"AR\":6, \"LA\":6, \"MS\":6, \"MO\":7 , \"IL\":7, \"IN\":7, \"OH\":7, \"KY\":7, \"TN\":7, \"WV\":7, \"AL\":8, \"VA\":8, \"NC\":8, \"SC\":8, \"GA\":8, \"FL\":8, \"DE\":9, \"DC\":9, \"MD\":9, \"PA\":9, \"NJ\":9, \"NY\":9, \"MA\":9, \"CT\":9, \"NH\":9, \"VT\":9, \"ME\":9, \"RI\":9}\n",
    "weather_key={1: \"Northwest\", 2: \"West\", 3: \"West North Central\", 4: \"Southwest\", 5: \"East North Central\", 6: \"South\", 7: \"Central\", 8: \"Southeast\", 9:\"Northeast\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(wnv_file_path, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing WNV yearly data and contructing a dataframe for it.\n",
    "df= pd.read_csv(wnv_file_path, encoding='latin-1')\n",
    "df=df[df[\"Select_County\"]==1]\n",
    "df.rename(columns = {'GEOID10':'GEOID'}, inplace = True)\n",
    "df=df[df[\"STNAME\"]!=\"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column for incident year (first year of WNV introduction) in the previous dataframe\n",
    "incident_year=[years[-1] for i in range(len(df))]\n",
    "for j in range(len(df)):\n",
    "    for i in years:\n",
    "        if(df.iloc[j][\"NI_IR_\" + str(i)]!=0):\n",
    "            incident_year[j]=i\n",
    "            break\n",
    "df[\"Incident_year\"]=incident_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with processing of 3 weather variables: temperature, precipitation and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file with weather (temperature, precipitation and humidity) data\n",
    "weather_data_path=\"/Users/sparshagarwal/Downloads/WMV_data/intersections/narr_urban_county_data_masked/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables in the data\n",
    "variables= [\"air.2m\", \"air.sfc\",\"apcp\", \"rhum.2m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding temp, precp, and humidity data\n",
    "df_mod=df.copy()\n",
    "for i in variables:\n",
    "    for j in years:\n",
    "        for k in range(len(months)):\n",
    "            #Importing monthly Variable data\n",
    "            data= pd.read_csv(weather_data_path + i +\"_masked/\"+ str(j) + \"_\" + months[k] + \"_masked.csv\")\n",
    "            data=data[[\"GEOID\", \"mean\"]]\n",
    "            data.rename(columns = {'mean': i + '_' + str(j) + \"_\" + months[k]}, inplace = True)\n",
    "            df_mod=df_mod.join(data.set_index('GEOID'), on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding socioeconomic and weather regions classification column\n",
    "sc=[]\n",
    "we=[]\n",
    "for i in range(len(df_mod)):\n",
    "    sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "df_mod[\"Socio_econ_class\"]=sc \n",
    "df_mod[\"Weather_class\"]=we"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking average across all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating average of mean summer temperature, precipitaion, humidity,  for every county and storing \n",
    "#all the corresponding attributes in different lists so that a simplified dataframe can be made.\n",
    "#Months considered with temperature lying in CDD_temp range.\n",
    "geo_id=[]\n",
    "mean_temp_2m=[]\n",
    "mean_temp_sfc=[]\n",
    "mean_prec=[]\n",
    "mean_hum=[]\n",
    "mean_cp=[]\n",
    "mean_ir=[]\n",
    "w_cl=[]\n",
    "s_cl=[]\n",
    "for i in range(len(df_mod)):\n",
    "    summer_temp_2m=[]\n",
    "    summer_temp_sfc=[]    \n",
    "    summer_prec=[]\n",
    "    summer_cp=[]\n",
    "    summer_hum=[]\n",
    "    summer_ir=[]\n",
    "    inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "                                     \n",
    "    for j in range(inc_year+1, years[-1]+1):\n",
    "        cdd_mon=[]\n",
    "        for k in months:\n",
    "            if(df_mod.iloc[i][variables[0]+ \"_\" + str(j) + \"_\" + k]>=a and df_mod.iloc[i][variables[0]+ \"_\" + str(j) + \"_\" + k]<=b):\n",
    "                cdd_mon.append(k)\n",
    "\n",
    "        avg_temp_2m=[]\n",
    "        avg_temp_sfc=[]    \n",
    "        avg_prec=[]\n",
    "        avg_hum=[]\n",
    "        for k in cdd_mon:\n",
    "            #Storing summer temp/prec/hum values for a certain year.\n",
    "            avg_temp_2m.append(df_mod.iloc[i][variables[0] + \"_\" + str(j) + \"_\" + k] -273)\n",
    "            avg_temp_sfc.append(df_mod.iloc[i][variables[1] + \"_\" + str(j) + \"_\" + k] -273)\n",
    "            avg_prec.append(df_mod.iloc[i][variables[2] + \"_\" + str(j) + \"_\" + k])\n",
    "            avg_hum.append(df_mod.iloc[i][variables[3] + \"_\" + str(j) + \"_\" + k])\n",
    "        #Calculating and storing the average summer temp/prec/hum value for a certain year.\n",
    "        summer_temp_2m.append(np.mean(avg_temp_2m))    \n",
    "        summer_temp_sfc.append(np.mean(avg_temp_sfc))\n",
    "        summer_prec.append(np.mean(avg_prec))\n",
    "        summer_cp.append(np.sum(avg_prec))      #For calculating cumulative precipitation\n",
    "        summer_hum.append(np.mean(avg_hum))\n",
    "        summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "                                   \n",
    "    if(inc_year!=years[-1]):\n",
    "        # Calculating mean of varaibles across all the years\n",
    "        mean_temp_2m.append(np.mean(summer_temp_2m))\n",
    "        mean_temp_sfc.append(np.mean(summer_temp_sfc))\n",
    "        mean_prec.append(np.mean(summer_prec))\n",
    "        mean_hum.append(np.mean(summer_hum))\n",
    "        mean_cp.append(np.mean(summer_cp))\n",
    "        mean_ir.append(np.mean(summer_ir))\n",
    "        geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "        w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "        s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a final dataframe containing values for each variable\n",
    "df_combined=pd.DataFrame()\n",
    "df_combined[\"GEOID\"]=geo_id\n",
    "df_combined[\"IR\"]=mean_ir\n",
    "df_combined[\"Temp_2m\"]=mean_temp_2m\n",
    "df_combined[\"Prec\"]=mean_prec\n",
    "df_combined[\"Hum\"]=mean_hum\n",
    "df_combined[\"Weather_class\"]=w_cl\n",
    "df_combined[\"Socio_econ_class\"]=s_cl\n",
    "df_combined=df_combined[df_combined[\"Temp_2m\"].isnull()==False]\n",
    "df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "for var in variables:\n",
    "    if(var==\"air.sfc\"):\n",
    "        continue\n",
    "    df_final=df_combined.copy()\n",
    "    if(var==\"air.2m\"):\n",
    "        var_name=\"Temp_2m\"\n",
    "        df_final.drop(columns=[\"Prec\",\"Hum\"], inplace=True)\n",
    "    if(var==\"apcp\"):\n",
    "        var_name=\"Prec\"\n",
    "        df_final.drop(columns=[\"Temp_2m\",\"Hum\"], inplace=True)\n",
    "    if(var==\"rhum.2m\"):\n",
    "        var_name=\"Hum\"\n",
    "        df_final.drop(columns=[\"Temp_2m\",\"Prec\"], inplace=True)\n",
    "    #To export data\n",
    "    df_final.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Weather_all_years_\" + var_name +\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking random sample years among all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_years=5    #Number of years to be sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating average of mean summer temperature, precipitaion, humidity,  for every county and storing \n",
    "#all the corresponding attributes in different lists so that a simplified dataframe can be made.\n",
    "#Months considered with temperature lying in CDD_temp range. Only \"n_sample_years\" number of years data is considered.\n",
    "geo_id=[]\n",
    "mean_temp_2m=[]\n",
    "mean_temp_sfc=[]\n",
    "mean_prec=[]\n",
    "mean_hum=[]\n",
    "mean_ir=[]\n",
    "w_cl=[]\n",
    "s_cl=[]\n",
    "for i in range(len(df_mod)):\n",
    "    summer_temp_2m=[]\n",
    "    summer_temp_sfc=[]    \n",
    "    summer_prec=[]\n",
    "    summer_hum=[]\n",
    "    summer_ir=[]\n",
    "    inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "    \n",
    "    sample_years=[]    # For storing n number of sample years\n",
    "    for rand in range(inc_year+1, years[-1]+1):\n",
    "        sample_years.append(rand)\n",
    "    random.seed(10)\n",
    "    if(len(sample_years)>n_sample_years):\n",
    "        sample_years=random.sample(sample_years,n_sample_years)\n",
    "        \n",
    "    for j in sample_years:\n",
    "        cdd_mon=[]\n",
    "        for k in months:\n",
    "            if(df_mod.iloc[i][variables[0]+ \"_\" + str(j) + \"_\" + k]>=a and df_mod.iloc[i][variables[0]+ \"_\" + str(j) + \"_\" + k]<=b):\n",
    "                cdd_mon.append(k)\n",
    "\n",
    "        avg_temp_2m=[]\n",
    "        avg_temp_sfc=[]    \n",
    "        avg_prec=[]\n",
    "        avg_hum=[]\n",
    "        for k in cdd_mon:\n",
    "            #Storing summer temp/prec/hum values for a certain year.\n",
    "            avg_temp_2m.append(df_mod.iloc[i][variables[0] + \"_\" + str(j) + \"_\" + k] -273)\n",
    "            avg_temp_sfc.append(df_mod.iloc[i][variables[1] + \"_\" + str(j) + \"_\" + k] -273)\n",
    "            avg_prec.append(df_mod.iloc[i][variables[2] + \"_\" + str(j) + \"_\" + k])\n",
    "            avg_hum.append(df_mod.iloc[i][variables[3] + \"_\" + str(j) + \"_\" + k])\n",
    "        #Calculating and storing the average summer temp/prec/hum value for a certain year.\n",
    "        summer_temp_2m.append(np.mean(avg_temp_2m))    \n",
    "        summer_temp_sfc.append(np.mean(avg_temp_sfc))\n",
    "        summer_prec.append(np.mean(avg_prec))\n",
    "        summer_hum.append(np.mean(avg_hum))\n",
    "        summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "                                   \n",
    "    if(inc_year!=years[-1]):\n",
    "        # Calculating mean of varaibles across all the sample years\n",
    "        mean_temp_2m.append(np.mean(summer_temp_2m))\n",
    "        mean_temp_sfc.append(np.mean(summer_temp_sfc))\n",
    "        mean_prec.append(np.mean(summer_prec))\n",
    "        mean_hum.append(np.mean(summer_hum))\n",
    "        mean_ir.append(np.mean(summer_ir))\n",
    "        geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "        w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "        s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a final dataframe containing values for each variable\n",
    "df_combined=pd.DataFrame()\n",
    "df_combined[\"GEOID\"]=geo_id\n",
    "df_combined[\"IR\"]=mean_ir\n",
    "df_combined[\"Temp_2m\"]=mean_temp_2m\n",
    "df_combined[\"Prec\"]=mean_prec\n",
    "df_combined[\"Hum\"]=mean_hum\n",
    "df_combined[\"Weather_class\"]=w_cl\n",
    "df_combined[\"Socio_econ_class\"]=s_cl\n",
    "df_combined=df_combined[df_combined[\"Temp_2m\"].isnull()==False]\n",
    "df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "for var in variables:\n",
    "    if(var==\"air.sfc\"):\n",
    "        continue\n",
    "    df_final=df_combined.copy()\n",
    "    if(var==\"air.2m\"):\n",
    "        var_name=\"Temp_2m\"\n",
    "        df_final.drop(columns=[\"Prec\",\"Hum\"], inplace=True)\n",
    "    if(var==\"apcp\"):\n",
    "        var_name=\"Prec\"\n",
    "        df_final.drop(columns=[\"Temp_2m\",\"Hum\"], inplace=True)\n",
    "    if(var==\"rhum.2m\"):\n",
    "        var_name=\"Hum\"\n",
    "        df_final.drop(columns=[\"Temp_2m\",\"Prec\"], inplace=True)\n",
    "    #To export data\n",
    "    df_final.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Weather_sample_years_\" + var_name +\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking median years values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating average of mean summer temperature, precipitaion, humidity,  for every county and storing \n",
    "#all the corresponding attributes in different lists so that a simplified dataframe can be made.\n",
    "#Months considered with temperature lying in CDD_temp range, not just May-Sept. Only median year values are considered.\n",
    "for median_variable in variables:   # Variable used to calculate median IR\n",
    "    geo_id=[]\n",
    "    mean_temp_2m=[]\n",
    "    mean_temp_sfc=[]\n",
    "    mean_prec=[]\n",
    "    mean_hum=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_temp_2m=[]\n",
    "        summer_temp_sfc=[]    \n",
    "        summer_prec=[]\n",
    "        summer_hum=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "\n",
    "        for j in range(inc_year+1, years[-1]+1):\n",
    "            cdd_mon=[]\n",
    "            for k in months:\n",
    "                if(df_mod.iloc[i][variables[0]+ \"_\" + str(j) + \"_\" + k]>=a and df_mod.iloc[i][variables[0]+ \"_\" + str(j) + \"_\" + k]<=b):\n",
    "                    cdd_mon.append(k)\n",
    "\n",
    "            avg_temp_2m=[]\n",
    "            avg_temp_sfc=[]    \n",
    "            avg_prec=[]\n",
    "            avg_hum=[]\n",
    "            for k in cdd_mon:\n",
    "                #Storing summer temp/prec/hum values for a certain year.\n",
    "                avg_temp_2m.append(df_mod.iloc[i][variables[0] + \"_\" + str(j) + \"_\" + k] -273)\n",
    "                avg_temp_sfc.append(df_mod.iloc[i][variables[1] + \"_\" + str(j) + \"_\" + k] -273)\n",
    "                avg_prec.append(df_mod.iloc[i][variables[2] + \"_\" + str(j) + \"_\" + k])\n",
    "                avg_hum.append(df_mod.iloc[i][variables[3] + \"_\" + str(j) + \"_\" + k])\n",
    "            #Calculating and storing the average summer temp/prec/hum value for a certain year.\n",
    "            summer_temp_2m.append(np.mean(avg_temp_2m))    \n",
    "            summer_temp_sfc.append(np.mean(avg_temp_sfc))\n",
    "            summer_prec.append(np.mean(avg_prec))\n",
    "            summer_hum.append(np.mean(avg_hum))\n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year!=years[-1]):\n",
    "            # Calculating median of variables across all the years\n",
    "            if(median_variable==variables[0]):\n",
    "                l=summer_temp_2m\n",
    "            elif(median_variable==variables[1]):\n",
    "                l=summer_temp_sfc\n",
    "            elif(median_variable==variables[2]):\n",
    "                l=summer_prec\n",
    "            elif(median_variable==variables[3]):\n",
    "                l=summer_hum\n",
    "            index=np.argsort(l)[len(l)//2]       #Index of median value\n",
    "            mean_temp_2m.append(summer_temp_2m[index])\n",
    "            mean_temp_sfc.append(summer_temp_sfc[index])\n",
    "            mean_prec.append(summer_prec[index])\n",
    "            mean_hum.append(summer_hum[index])\n",
    "            mean_ir.append(summer_ir[index])     #Median IR corresponding to the variable of interest\n",
    "\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "            \n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[\"Temp_2m\"]=mean_temp_2m\n",
    "    df_combined[\"Prec\"]=mean_prec\n",
    "    df_combined[\"Hum\"]=mean_hum\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    df_combined=df_combined[df_combined[\"Temp_2m\"].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    for var in variables:\n",
    "        if(median_variable==\"air.sfc\"):\n",
    "            continue\n",
    "        df_final=df_combined.copy()\n",
    "        if(median_variable==\"air.2m\"):\n",
    "            var_name=\"Temp_2m\"\n",
    "            df_final.drop(columns=[\"Prec\",\"Hum\"], inplace=True)\n",
    "        if(median_variable==\"apcp\"):\n",
    "            var_name=\"Prec\"\n",
    "            df_final.drop(columns=[\"Temp_2m\",\"Hum\"], inplace=True)\n",
    "        if(median_variable==\"rhum.2m\"):\n",
    "            var_name=\"Hum\"\n",
    "            df_final.drop(columns=[\"Temp_2m\",\"Prec\"], inplace=True)\n",
    "        #To export data\n",
    "        df_final.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Weather_median_years_\" + var_name +\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with processing of weather variables other than temperature, precipitation and humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking average across all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=[\"filtered_aggregated_precipitation\", \"dry_days_filtered\", \"max_consecutive_dry_days\", \"gini_index_summer\", \"gini_index\", \"gini_weekly\", \"theil_index_summer\", \"theil_index\", \"theil_weekly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"filtered_aggregated_precipitation\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/aggregate/\"+ variable + \".csv\"\n",
    "    if(variable==\"dry_days_filtered\" or variable==\"max_consecutive_dry_days\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/dry_days/\"+ variable + \".csv\"\n",
    "    if(variable==\"gini_index_summer\" or variable==\"gini_index\" or variable==\"gini_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/gini/\"+ variable + \".csv\"\n",
    "    if(variable==\"theil_index_summer\" or variable==\"theil_index\" or variable==\"theil_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/theil/\"+ variable + \".csv\"\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    df_mod=df_mod.join(data.set_index('GEOID'), on='GEOID')\n",
    "    \n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "    \n",
    "    #Calculating average of yearly variable across all years for every county and storing \n",
    "    #all the corresponding attributes in different lists so that a simplified dataframe can be made.\n",
    "    #Months considered with temperature lying in CDD_temp range.\n",
    "    geo_id=[]\n",
    "    mean_variable=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_variable=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "\n",
    "        for j in range(inc_year+1, years[-1]+1):\n",
    "            #Calculating and storing the variable value for a certain year.\n",
    "            summer_variable.append(df_mod.iloc[i][str(j)])    \n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year!=years[-1]):\n",
    "            # Calculating mean of variable across all the years\n",
    "            mean_variable.append(np.mean(summer_variable))\n",
    "            mean_ir.append(np.mean(summer_ir))\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "            \n",
    "    #For average across all the years\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[variable]=mean_variable\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    \n",
    "    df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    \n",
    "    #To export data\n",
    "    df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Weather_all_years_\" + variable + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking random sample years among all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_years=5    #Number of years to be sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"filtered_aggregated_precipitation\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/aggregate/\"+ variable + \".csv\"\n",
    "    if(variable==\"dry_days_filtered\" or variable==\"max_consecutive_dry_days\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/dry_days/\"+ variable + \".csv\"\n",
    "    if(variable==\"gini_index_summer\" or variable==\"gini_index\" or variable==\"gini_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/gini/\"+ variable + \".csv\"\n",
    "    if(variable==\"theil_index_summer\" or variable==\"theil_index\" or variable==\"theil_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/theil/\"+ variable + \".csv\"\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    df_mod=df_mod.join(data.set_index('GEOID'), on='GEOID')\n",
    "    \n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "\n",
    "#Calculating average of yearly variable values for every county, and storing all the corresponding attributes \n",
    "#in different lists so that a simplified dataframe can be made. Only \"n_sample_years\" number of years data is considered.\n",
    "    geo_id=[]\n",
    "    mean_variable=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_variable=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "\n",
    "        sample_years=[]    # For storing n number of sample years\n",
    "        for rand in range(inc_year+1, years[-1]+1):\n",
    "            sample_years.append(rand)\n",
    "        random.seed(10)\n",
    "        if(len(sample_years)>n_sample_years):\n",
    "            sample_years=random.sample(sample_years,n_sample_years)\n",
    "\n",
    "        for j in sample_years:\n",
    "            #Calculating and storing the variable value for a certain year.\n",
    "            summer_variable.append(df_mod.iloc[i][str(j)])    \n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year!=years[-1]):\n",
    "            # Calculating mean of varaible across all the years\n",
    "            mean_variable.append(np.mean(summer_variable))\n",
    "            mean_ir.append(np.mean(summer_ir))\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "    \n",
    "    #For average across all the sample years\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[variable]=mean_variable\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    \n",
    "    df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    \n",
    "    #To export data\n",
    "    df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Weather_sample_years_\" + variable + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking median years values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"filtered_aggregated_precipitation\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/aggregate/\"+ variable + \".csv\"\n",
    "    if(variable==\"dry_days_filtered\" or variable==\"max_consecutive_dry_days\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/dry_days/\"+ variable + \".csv\"\n",
    "    if(variable==\"gini_index_summer\" or variable==\"gini_index\" or variable==\"gini_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/gini/\"+ variable + \".csv\"\n",
    "    if(variable==\"theil_index_summer\" or variable==\"theil_index\" or variable==\"theil_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/theil/\"+ variable + \".csv\"\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    df_mod=df_mod.join(data.set_index('GEOID'), on='GEOID')\n",
    "    \n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "\n",
    "#Calculating median of yearly variable values for every county, and storing all the corresponding attributes \n",
    "#in different lists so that a simplified dataframe can be made. \n",
    "    geo_id=[]\n",
    "    mean_variable=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_variable=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "\n",
    "        for j in range(inc_year+1, years[-1]+1):\n",
    "            #Calculating and storing the variable value for a certain year.\n",
    "            summer_variable.append(df_mod.iloc[i][str(j)])    \n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year!=years[-1]):\n",
    "            # Calculating median of varaible across all the years\n",
    "            l=summer_variable\n",
    "            index=np.argsort(l)[len(l)//2]       #Index of median value\n",
    "            mean_variable.append(summer_variable[index])\n",
    "            mean_ir.append(summer_ir[index])     #Median corresponding to the variable of interest\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "        \n",
    "    \n",
    "    #For average across all the sample years\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[variable]=mean_variable\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    \n",
    "    df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    \n",
    "    #To export data\n",
    "    df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Weather_median_years_\" + variable + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with processing of socio-economic variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking average across all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=[\"Resident_population_White_alone_percent\", \"Median_Household_Income\", \"Poverty_percent_of_people\", \"Median_Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"Poverty_percent_of_people\" or variable==\"Median_Household_Income\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/se_data.csv\"\n",
    "        years=range(1999, 2010)\n",
    "    if(variable==\"Resident_population_White_alone_percent\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/race_data.csv\"\n",
    "        years=range(2000, 2010)\n",
    "    if(variable==\"Median_Age\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/age.csv\"\n",
    "        years=[2000, 2010]\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    temp_df=pd.DataFrame()\n",
    "    #Creating dataframe of socio economic variable\n",
    "    for i in years:\n",
    "        data_f=data[data[\"YEAR\"]==i]\n",
    "        geo_id=[]\n",
    "        var_value=[]\n",
    "        for j in range(1,len(data_f)):\n",
    "            geo_id.append(data_f.iloc[j][\"STCOU\"])\n",
    "            var_value.append(data_f.iloc[j][variable])\n",
    "        temp_df[\"GEOID\"]=geo_id\n",
    "        temp_df[variable + \"_\" + str(i)]=var_value\n",
    "    #The main dataframe comprising of everything\n",
    "    df_mod=df_mod.join(temp_df.set_index('GEOID'), on='GEOID')\n",
    "\n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "    \n",
    "    #Calculating average of yearly variable across all years for every county and storing \n",
    "    #all the corresponding attributes in different lists so that a simplified dataframe can be made.\n",
    "    geo_id=[]\n",
    "    mean_variable=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_variable=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "        \n",
    "        years_list=[]\n",
    "        if(inc_year<years[-1]):\n",
    "            if(inc_year in years):\n",
    "                idx_incident=years.index(inc_year)               \n",
    "            else:\n",
    "                for j in years:\n",
    "                    if(inc_year<j):\n",
    "                        idx_incident=years.index(j)-1\n",
    "                        break\n",
    "\n",
    "        for k in range(idx_incident+1,len(years)):\n",
    "                    years_list.append(years[k])\n",
    "                \n",
    "        for j in years_list:\n",
    "            #Calculating and storing the variable value for a certain year.\n",
    "            summer_variable.append(df_mod.iloc[i][variable + \"_\" + str(j)])    \n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year<years[-1]):\n",
    "            # Calculating mean of variable across all the years\n",
    "            mean_variable.append(np.mean(summer_variable))\n",
    "            mean_ir.append(np.mean(summer_ir))\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "            \n",
    "    #For average across all the years\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[variable]=mean_variable\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    \n",
    "    df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    \n",
    "    #To export data\n",
    "    df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Socio_all_years_\" + variable + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking random sample years among all the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_years=5    #Number of years to be sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"Poverty_percent_of_people\" or variable==\"Median_Household_Income\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/se_data.csv\"\n",
    "        years=range(1999, 2010)\n",
    "    if(variable==\"Resident_population_White_alone_percent\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/race_data.csv\"\n",
    "        years=range(2000, 2010)\n",
    "    if(variable==\"Median_Age\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/age.csv\"\n",
    "        years=[2000, 2010]\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    temp_df=pd.DataFrame()\n",
    "    #Creating dataframe of socio economic variable\n",
    "    for i in years:\n",
    "        data_f=data[data[\"YEAR\"]==i]\n",
    "        geo_id=[]\n",
    "        var_value=[]\n",
    "        for j in range(1,len(data_f)):\n",
    "            geo_id.append(data_f.iloc[j][\"STCOU\"])\n",
    "            var_value.append(data_f.iloc[j][variable])\n",
    "        temp_df[\"GEOID\"]=geo_id\n",
    "        temp_df[variable + \"_\" + str(i)]=var_value\n",
    "    #The main dataframe comprising of everything\n",
    "    df_mod=df_mod.join(temp_df.set_index('GEOID'), on='GEOID')\n",
    "\n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "    \n",
    "    #Calculating average of yearly variable values for every county, and storing all the corresponding attributes \n",
    "    #in different lists so that a simplified dataframe can be made. Only \"n_sample_years\" number of years data is considered.\n",
    "    geo_id=[]\n",
    "    mean_variable=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_variable=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "\n",
    "        sample_years=[]    # For storing n number of sample years\n",
    "        for rand in range(inc_year+1, years[-1]+1):\n",
    "            sample_years.append(rand)\n",
    "        random.seed(10)\n",
    "        if(len(sample_years)>n_sample_years):\n",
    "            sample_years=random.sample(sample_years,n_sample_years)\n",
    "    \n",
    "        sample_years=list(set(sample_years) & set(years)) \n",
    "        \n",
    "        years_list=[]\n",
    "        if(len(sample_years)!=0):\n",
    "            if(inc_year<sample_years[-1]):\n",
    "                if(inc_year in sample_years):\n",
    "                    idx_incident=sample_years.index(inc_year)               \n",
    "                else:\n",
    "                    for j in sample_years:\n",
    "                        if(inc_year<j):\n",
    "                            idx_incident=sample_years.index(j)-1\n",
    "                            break\n",
    "\n",
    "        for k in range(idx_incident+1,len(sample_years)):\n",
    "                    years_list.append(sample_years[k])    \n",
    "\n",
    "        for j in years_list:\n",
    "            #Calculating and storing the variable value for a certain year.\n",
    "            summer_variable.append(df_mod.iloc[i][variable + \"_\" + str(j)])    \n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year<years[-1]):\n",
    "            # Calculating mean of variable across all the years\n",
    "            mean_variable.append(np.mean(summer_variable))\n",
    "            mean_ir.append(np.mean(summer_ir))\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])\n",
    "            \n",
    "    #For average across all the years\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[variable]=mean_variable\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    \n",
    "    df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    \n",
    "    #To export data\n",
    "    df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Socio_sample_years_\" + variable + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the values by taking median years values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"Poverty_percent_of_people\" or variable==\"Median_Household_Income\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/se_data.csv\"\n",
    "        years=range(1999, 2010)\n",
    "    if(variable==\"Resident_population_White_alone_percent\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/race_data.csv\"\n",
    "        years=range(2000, 2010)\n",
    "    if(variable==\"Median_Age\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/age.csv\"\n",
    "        years=[2000, 2010]\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    temp_df=pd.DataFrame()\n",
    "    #Creating dataframe of socioeconomic variable\n",
    "    for i in years:\n",
    "        data_f=data[data[\"YEAR\"]==i]\n",
    "        geo_id=[]\n",
    "        var_value=[]\n",
    "        for j in range(1,len(data_f)):\n",
    "            geo_id.append(data_f.iloc[j][\"STCOU\"])\n",
    "            var_value.append(data_f.iloc[j][variable])\n",
    "        temp_df[\"GEOID\"]=geo_id\n",
    "        temp_df[variable + \"_\" + str(i)]=var_value\n",
    "    #The main dataframe comprising of everything\n",
    "    df_mod=df_mod.join(temp_df.set_index('GEOID'), on='GEOID')\n",
    "\n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "    \n",
    "#Calculating median of yearly variable values for every county, and storing all the corresponding attributes \n",
    "#in different lists so that a simplified dataframe can be made.\n",
    "    geo_id=[]\n",
    "    mean_variable=[]\n",
    "    mean_ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        summer_variable=[]\n",
    "        summer_ir=[]\n",
    "        inc_year= df_mod.iloc[i][\"Incident_year\"]  # 1st year of WNV incidence\n",
    "\n",
    "        years_list=[]\n",
    "        if(inc_year<years[-1]):\n",
    "            if(inc_year in years):\n",
    "                idx_incident=years.index(inc_year)               \n",
    "            else:\n",
    "                for j in years:\n",
    "                    if(inc_year<j):\n",
    "                        idx_incident=years.index(j)-1\n",
    "                        break\n",
    "\n",
    "        for k in range(idx_incident+1,len(years)):\n",
    "                    years_list.append(years[k])\n",
    "                \n",
    "        for j in years_list:\n",
    "            #Calculating and storing the variable value for a certain year.\n",
    "            summer_variable.append(df_mod.iloc[i][variable + \"_\" + str(j)])    \n",
    "            summer_ir.append(df_mod.iloc[i][\"NI_IR_\" + str(j)])\n",
    "\n",
    "        if(inc_year<years[-1]):\n",
    "            # Calculating median of variable across all the years\n",
    "            l=summer_variable\n",
    "            index=np.argsort(l)[len(l)//2]       #Index of median value\n",
    "            mean_variable.append(summer_variable[index])\n",
    "            mean_ir.append(summer_ir[index])     #Median corresponding to the variable of interest\n",
    "            geo_id.append(df_mod.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_mod.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_mod.iloc[i][\"Socio_econ_class\"])       \n",
    "            \n",
    "    #For average across all the years\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=mean_ir\n",
    "    df_combined[variable]=mean_variable\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    \n",
    "    df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "    df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    \n",
    "    #To export data\n",
    "    df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal/Socio_median_years_\" + variable + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for generating dataframes for chi-sqaure calculation for every variable, for entire USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where the normal datframes are stored\n",
    "folder_path=\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    data_path= folder_path + \"/\" + file\n",
    "    data= pd.read_csv(data_path)\n",
    "    variable=data.columns[2]    #Variable for chi-square test\n",
    "    \n",
    "    #Average of IR and the variable for classification purpose\n",
    "    temp_data=pd.read_csv(folder_path + \"/\" + file)   # For calculating average value of the variable for chi square classification\n",
    "    avg_ir=np.mean(temp_data[\"IR\"])\n",
    "    avg_var=np.mean(temp_data[variable])\n",
    "    l=[]\n",
    "    for i in range(len(data)):\n",
    "        if(data.iloc[i][\"IR\"]>=avg_ir):\n",
    "            l.append(\"H\")\n",
    "        else:\n",
    "            l.append(\"L\")\n",
    "    data[\"Class_IR\"]=l\n",
    "    l=[]\n",
    "    for i in range(len(data)):\n",
    "        if(data.iloc[i][variable]>=avg_var):\n",
    "            l.append(\"H\")\n",
    "        else:\n",
    "            l.append(\"L\")\n",
    "    data[\"Class_var\"]=l\n",
    "    #To export data\n",
    "    data.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Chi/USA/\" + file[:(len(file)-4)] + \"_chi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for generating dataframes for chi-square calculation for every variable, for entire USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    data_path= folder_path + \"/\" + file\n",
    "    data= pd.read_csv(data_path)\n",
    "    variable=data.columns[2]    #Variable for chi-square test\n",
    "    \n",
    "    dic_ir={}  #To store average IR for each individual zone\n",
    "    dic_var={} #To store average variable value for each individual zone\n",
    "    for i in range(1,10):    #Iterating over weather/climate zones\n",
    "        df_temp=data[data[\"Weather_class\"]==i]\n",
    "        #Average of IR and the variable for classification purpose\n",
    "        avg_ir=np.mean(df_temp[\"IR\"])\n",
    "        avg_var=np.mean(df_temp[variable])\n",
    "        dic_ir[i]=avg_ir\n",
    "        dic_var[i]=avg_var\n",
    "    l=[]\n",
    "    for i in range(len(data)):\n",
    "        if(data.iloc[i][\"IR\"]>=dic_ir[int(data.iloc[i][\"Weather_class\"])]):\n",
    "            l.append(\"H\")\n",
    "        else:\n",
    "            l.append(\"L\")\n",
    "    data[\"Class_IR\"]=l\n",
    "\n",
    "    l=[]\n",
    "    for i in range(len(data)):\n",
    "        if(data.iloc[i][variable]>=dic_var[int(data.iloc[i][\"Weather_class\"])]):\n",
    "            l.append(\"H\")\n",
    "        else:\n",
    "            l.append(\"L\")\n",
    "    data[\"Class_var\"]=l\n",
    "    #To export data\n",
    "    data.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Chi/Zone_wise/\" + file[:(len(file)-4)] + \"_chi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining data/variables from all the dataframes and calculating VIF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where the normal dataframes are stored\n",
    "folder_path=\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Normal\"\n",
    "files=os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering all the \"all_years\" files\n",
    "data_files=[]\n",
    "for file in files:\n",
    "    if(file[0]==\"S\"):  #Socio-economic variable\n",
    "        if(file[6]==\"a\"):   # All years file\n",
    "            data_files.append(file)\n",
    "    elif(file[0]==\"W\"):  #Weather variable\n",
    "        if(file[8]==\"a\"):   # All years file\n",
    "            data_files.append(file)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.read_csv(folder_path + \"/\" + data_files[0])\n",
    "cols=main_df.columns\n",
    "main_df=main_df[[cols[0], cols[1], cols[2]]]\n",
    "a=[]\n",
    "for file in data_files[1::]:\n",
    "    temp_df=pd.read_csv(folder_path + \"/\" + file)\n",
    "    cols=temp_df.columns\n",
    "    a.append(len(temp_df))\n",
    "    if(len(temp_df)==114):\n",
    "        continue\n",
    "    temp_df=temp_df[[cols[0], cols[2]]]\n",
    "    main_df=main_df.join(temp_df.set_index('GEOID'), on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=main_df[main_df[\"Median_Household_Income\"].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the dataframe\n",
    "main_df.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Combined/Average_years.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(main_df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=main_df.columns[1:]\n",
    "X = main_df[cols]\n",
    "X['Intercept'] = 1\n",
    "# Compute and view VIF\n",
    "vif = pd.DataFrame()\n",
    "vif[\"variables\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i).round(1) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>max_consecutive_dry_days</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Median_Household_Income</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gini_index_summer</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>theil_weekly</td>\n",
       "      <td>104.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>filtered_aggregated_precipitation</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>gini_index</td>\n",
       "      <td>456.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Resident_population_White_alone_percent</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Temp_2m</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>gini_weekly</td>\n",
       "      <td>79.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>theil_index</td>\n",
       "      <td>863.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>dry_days_filtered</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Hum</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Poverty_percent_of_people</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>theil_index_summer</td>\n",
       "      <td>955.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Prec</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>557265083.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  variables          VIF\n",
       "0                  max_consecutive_dry_days         10.4\n",
       "1                   Median_Household_Income          3.9\n",
       "2                         gini_index_summer        457.0\n",
       "3                              theil_weekly        104.4\n",
       "4         filtered_aggregated_precipitation          6.5\n",
       "5                                gini_index        456.1\n",
       "6   Resident_population_White_alone_percent          1.9\n",
       "7                                   Temp_2m          5.6\n",
       "8                               gini_weekly         79.2\n",
       "9                               theil_index        863.5\n",
       "10                        dry_days_filtered          7.6\n",
       "11                                      Hum          7.1\n",
       "12                Poverty_percent_of_people          5.2\n",
       "13                       theil_index_summer        955.8\n",
       "14                                     Prec         11.2\n",
       "15                                Intercept  557265083.3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making mutiple combined dataframes for every individual year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generating year wise data for temp, hum and prec based on CDD months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=range(1999, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file with weather (temperature, precipitation and humidity) data\n",
    "weather_data_path=\"/Users/sparshagarwal/Downloads/WMV_data/intersections/narr_urban_county_data_masked/\"\n",
    "# Variables in the data\n",
    "variables= [\"air.2m\",\"apcp\", \"rhum.2m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding temp, precp, and humidity data\n",
    "df_mod=df.copy()\n",
    "for i in variables:\n",
    "    for j in years:\n",
    "        for k in range(len(months)):\n",
    "            #Importing monthly Variable data\n",
    "            data= pd.read_csv(weather_data_path + i +\"_masked/\"+ str(j) + \"_\" + months[k] + \"_masked.csv\")\n",
    "            data=data[[\"GEOID\", \"mean\"]]\n",
    "            data.rename(columns = {'mean': i + '_' + str(j) + \"_\" + months[k]}, inplace = True)\n",
    "            df_mod=df_mod.join(data.set_index('GEOID'), on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding socioeconomic and weather regions classification column\n",
    "sc=[]\n",
    "we=[]\n",
    "for i in range(len(df_mod)):\n",
    "    sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "df_mod[\"Socio_econ_class\"]=sc \n",
    "df_mod[\"Weather_class\"]=we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#Generating year wise dataframe for temp, prec and humidity.\n",
    "\n",
    "years=range(1999, 2016)\n",
    "\n",
    "for year in years:\n",
    "    geo_id=[]\n",
    "    temp_2m=[]\n",
    "    prec=[]\n",
    "    hum=[]\n",
    "    ir=[]\n",
    "    w_cl=[]\n",
    "    s_cl=[]\n",
    "    df_filter=df_mod[df_mod[\"Incident_year\"]<year]\n",
    "    for i in range(len(df_filter)):\n",
    "        cdd_mon=[]\n",
    "        for k in months:\n",
    "            if(df_filter.iloc[i][variables[0]+ \"_\" + str(year) + \"_\" + k]>=a and df_filter.iloc[i][variables[0]+ \"_\" + str(year) + \"_\" + k]<=b):\n",
    "                cdd_mon.append(k)\n",
    "        \n",
    "        avg_temp_2m=[]   \n",
    "        avg_prec=[]\n",
    "        avg_hum=[]\n",
    "        \n",
    "        for k in cdd_mon:\n",
    "            #Storing summer temp/prec/hum values for a certain year.\n",
    "            avg_temp_2m.append(df_filter.iloc[i][variables[0] + \"_\" + str(year) + \"_\" + k] -273)\n",
    "            avg_prec.append(df_filter.iloc[i][variables[1] + \"_\" + str(year) + \"_\" + k])\n",
    "            avg_hum.append(df_filter.iloc[i][variables[2] + \"_\" + str(year) + \"_\" + k])\n",
    "            \n",
    "        #Calculating and storing the average summer temp/prec/hum value for a certain year.\n",
    "        temp_2m.append(np.mean(avg_temp_2m))    \n",
    "        prec.append(np.mean(avg_prec))\n",
    "        hum.append(np.mean(avg_hum))\n",
    "        ir.append(df_filter.iloc[i][\"NI_IR_\" + str(year)])\n",
    "        geo_id.append(df_filter.iloc[i][\"GEOID\"])\n",
    "        w_cl.append(df_filter.iloc[i][\"Weather_class\"])\n",
    "        s_cl.append(df_filter.iloc[i][\"Socio_econ_class\"])\n",
    "    df_combined=pd.DataFrame()\n",
    "    df_combined[\"GEOID\"]=geo_id\n",
    "    df_combined[\"IR\"]=ir\n",
    "    df_combined[\"Temp_2m\"]=temp_2m\n",
    "    df_combined[\"Prec\"]=prec\n",
    "    df_combined[\"Hum\"]=hum\n",
    "    df_combined[\"Weather_class\"]=w_cl\n",
    "    df_combined[\"Socio_econ_class\"]=s_cl\n",
    "    df_combined=df_combined[df_combined[\"Temp_2m\"].isnull()==False]\n",
    "    #df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "    for var in variables:\n",
    "        df_final=df_combined.copy()\n",
    "        if(var==\"air.2m\"):\n",
    "            var_name=\"Temp_2m\"\n",
    "            df_final.drop(columns=[\"Prec\",\"Hum\"], inplace=True)\n",
    "        if(var==\"apcp\"):\n",
    "            var_name=\"Prec\"\n",
    "            df_final.drop(columns=[\"Temp_2m\",\"Hum\"], inplace=True)\n",
    "        if(var==\"rhum.2m\"):\n",
    "            var_name=\"Hum\"\n",
    "            df_final.drop(columns=[\"Temp_2m\",\"Prec\"], inplace=True)\n",
    "        #To export data\n",
    "        df_final.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Individual_years/\" + var_name + \"_\" + str(year)+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generating year wise data for remaining environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=[\"filtered_aggregated_precipitation\", \"dry_days_filtered\", \"max_consecutive_dry_days\", \"gini_index_summer\", \"gini_index\", \"gini_weekly\", \"theil_index_summer\", \"theil_index\", \"theil_weekly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=range(1999,2016)\n",
    "for variable in variables:\n",
    "    if(variable==\"filtered_aggregated_precipitation\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/aggregate/\"+ variable + \".csv\"\n",
    "    if(variable==\"dry_days_filtered\" or variable==\"max_consecutive_dry_days\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/dry_days/\"+ variable + \".csv\"\n",
    "    if(variable==\"gini_index_summer\" or variable==\"gini_index\" or variable==\"gini_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/gini/\"+ variable + \".csv\"\n",
    "    if(variable==\"theil_index_summer\" or variable==\"theil_index\" or variable==\"theil_weekly\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/urban_county_indices/theil/\"+ variable + \".csv\"\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    df_mod=df_mod.join(data.set_index('GEOID'), on='GEOID')\n",
    "    \n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "    \n",
    "    for year in years:\n",
    "        geo_id=[]\n",
    "        var=[]\n",
    "        ir=[]\n",
    "        w_cl=[]\n",
    "        s_cl=[]\n",
    "        df_filter=df_mod[df_mod[\"Incident_year\"]<year]\n",
    "        for i in range(len(df_filter)):\n",
    "            var.append(df_filter.iloc[i][str(year)])\n",
    "            ir.append(df_filter.iloc[i][\"NI_IR_\" + str(year)])\n",
    "            geo_id.append(df_filter.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_filter.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_filter.iloc[i][\"Socio_econ_class\"])\n",
    "        df_combined=pd.DataFrame()\n",
    "        df_combined[\"GEOID\"]=geo_id\n",
    "        df_combined[\"IR\"]=ir\n",
    "        df_combined[variable]=var\n",
    "        df_combined[\"Weather_class\"]=w_cl\n",
    "        df_combined[\"Socio_econ_class\"]=s_cl\n",
    "        df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "        #df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "        df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Individual_years/\" + variable + \"_\" + str(year)+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generating year wise data for socioeconomic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=[\"Resident_population_White_alone_percent\", \"Median_Household_Income\", \"Poverty_percent_of_people\", \"Median_Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    if(variable==\"Poverty_percent_of_people\" or variable==\"Median_Household_Income\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/se_data.csv\"\n",
    "        years=range(1999, 2010)\n",
    "    if(variable==\"Resident_population_White_alone_percent\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/race_data.csv\"\n",
    "        years=range(2000, 2010)\n",
    "    if(variable==\"Median_Age\"):\n",
    "        data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/age.csv\"\n",
    "        years=[2000, 2010]\n",
    "    # Adding data for the variable\n",
    "    df_mod=df.copy()\n",
    "    data=pd.read_csv(data_path)\n",
    "    temp_df=pd.DataFrame()\n",
    "    #Creating dataframe of socio economic variable\n",
    "    for i in years:\n",
    "        data_f=data[data[\"YEAR\"]==i]\n",
    "        geo_id=[]\n",
    "        var_value=[]\n",
    "        for j in range(1,len(data_f)):\n",
    "            geo_id.append(data_f.iloc[j][\"STCOU\"])\n",
    "            var_value.append(data_f.iloc[j][variable])\n",
    "        temp_df[\"GEOID\"]=geo_id\n",
    "        temp_df[variable + \"_\" + str(i)]=var_value\n",
    "    #The main dataframe comprising of everything\n",
    "    df_mod=df_mod.join(temp_df.set_index('GEOID'), on='GEOID')\n",
    "\n",
    "    #Adding socioeconomic and weather regions classification column\n",
    "    sc=[]\n",
    "    we=[]\n",
    "    for i in range(len(df_mod)):\n",
    "        sc.append(socio_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "        we.append(weather_regions[df_mod.iloc[i][\"STUSPS\"]])\n",
    "    df_mod[\"Socio_econ_class\"]=sc \n",
    "    df_mod[\"Weather_class\"]=we\n",
    "   \n",
    "    \n",
    "    for year in years:\n",
    "        geo_id=[]\n",
    "        var=[]\n",
    "        ir=[]\n",
    "        w_cl=[]\n",
    "        s_cl=[]\n",
    "        df_filter=df_mod[df_mod[\"Incident_year\"]<year]\n",
    "        for i in range(len(df_filter)):\n",
    "            var.append(df_filter.iloc[i][variable + \"_\" + str(year)])\n",
    "            ir.append(df_filter.iloc[i][\"NI_IR_\" + str(year)])\n",
    "            geo_id.append(df_filter.iloc[i][\"GEOID\"])\n",
    "            w_cl.append(df_filter.iloc[i][\"Weather_class\"])\n",
    "            s_cl.append(df_filter.iloc[i][\"Socio_econ_class\"])\n",
    "        df_combined=pd.DataFrame()\n",
    "        df_combined[\"GEOID\"]=geo_id\n",
    "        df_combined[\"IR\"]=ir\n",
    "        df_combined[variable]=var\n",
    "        df_combined[\"Weather_class\"]=w_cl\n",
    "        df_combined[\"Socio_econ_class\"]=s_cl\n",
    "        df_combined=df_combined[df_combined[variable].isnull()==False]\n",
    "        #df_combined=df_combined[df_combined[\"IR\"]!=0]   # Removing entries with IR=0\n",
    "        df_combined.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Individual_years/\" + variable + \"_\" + str(year)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now incorporating all the variables into a single dataframe for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=range(2000,2010)\n",
    "variables=['max_consecutive_dry_days', 'Median_Household_Income',\n",
    "'gini_index_summer', 'theil_weekly',\n",
    "       'filtered_aggregated_precipitation', 'gini_index',\n",
    "       'Resident_population_White_alone_percent', 'Temp_2m', 'gini_weekly',\n",
    "       'theil_index', 'dry_days_filtered', 'Hum', 'Poverty_percent_of_people',\n",
    "       'theil_index_summer', 'Prec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years=range(2000,2016)\n",
    "# variables=['max_consecutive_dry_days',\n",
    "# 'gini_index_summer', 'theil_weekly',\n",
    "#        'filtered_aggregated_precipitation', 'gini_index', 'Temp_2m', 'gini_weekly',\n",
    "#        'theil_index', 'dry_days_filtered', 'Hum',\n",
    "#        'theil_index_summer', 'Prec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entire=pd.DataFrame()   ### The main dataframe\n",
    "for year in years:\n",
    "    df_all=pd.read_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Individual_years/\" + variables[0] + \"_\" + str(year)+\".csv\")\n",
    "    df_all=df_all[[\"GEOID\", \"IR\", variables[0]]]\n",
    "    for var in variables[1:]:\n",
    "        data=pd.read_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Individual_years/\" + var + \"_\" + str(year)+\".csv\")\n",
    "        data=data[[\"GEOID\", var]]\n",
    "        df_all=df_all.join(data.set_index('GEOID'), on='GEOID')\n",
    "    df_entire=pd.concat([df_entire,df_all])\n",
    "    \n",
    "df_entire.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Combined/Individual_years.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
