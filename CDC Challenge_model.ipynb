{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import itertools  \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "#Loading the data with State Avg column\n",
    "\n",
    "cdc = pd.read_csv('/Users/sparshagarwal/Desktop/NCSA/Dataframes/WNV_challenge_neighCountyAvg.csv')\n",
    "\n",
    "#Changes/Cleaning that needs to be done in data as mentioned by the cdc manual\n",
    "\n",
    "cdc['county'] = np.where(cdc['county']=='Bedford/Bedford City', 'Bedford', cdc['county'])\n",
    "cdc['fips'] = np.where(cdc['fips']=='51019/51515', '51019', cdc['fips'])\n",
    "cdc['location'] = np.where(cdc['location']=='Virginia-Bedford/Bedford City', 'Virginia-Bedford', cdc['location'])\n",
    "\n",
    "cdc['county'] = np.where(cdc['county']=='Oglala Lakota/Shannon', 'Oglala Lakota', cdc['county'])\n",
    "cdc['fips'] = np.where(cdc['fips']=='46102/46113', '46102', cdc['fips'])\n",
    "cdc['location'] = np.where(cdc['location']=='South Dakota-Oglala Lakota/Shannon', 'South Dakota-Oglala Lakota', cdc['location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting fips from object/string to int datatype\n",
    "\n",
    "cdc['fips']=cdc['fips'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_dummy={1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[], 10:[], 11:[], 12:[], 13:[], 14:[], 15:[]}\n",
    "\n",
    "for i in range(len(cdc)):\n",
    "    cl=cdc.iloc[i][\"bin\"]\n",
    "    for j in bin_dummy:\n",
    "        bin_dummy[j].append(0)\n",
    "    bin_dummy[cl][-1]=1\n",
    "    \n",
    "for i in bin_dummy:\n",
    "    cdc[i]=bin_dummy[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>bin</th>\n",
       "      <th>neigh_death_count</th>\n",
       "      <th>num_of_neighbor</th>\n",
       "      <th>neighborCountyAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama-Autauga</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama-Autauga</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama-Autauga</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama-Autauga</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama-Autauga</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips   county    state         location  year  count  bin  \\\n",
       "0  1001  Autauga  Alabama  Alabama-Autauga  2000      0    1   \n",
       "1  1001  Autauga  Alabama  Alabama-Autauga  2001      0    1   \n",
       "2  1001  Autauga  Alabama  Alabama-Autauga  2002      1    2   \n",
       "3  1001  Autauga  Alabama  Alabama-Autauga  2003      0    1   \n",
       "4  1001  Autauga  Alabama  Alabama-Autauga  2004      0    1   \n",
       "\n",
       "   neigh_death_count  num_of_neighbor  neighborCountyAvg  ...  6  7  8  9  10  \\\n",
       "0                  0                5                0.0  ...  0  0  0  0   0   \n",
       "1                  0                5                0.0  ...  0  0  0  0   0   \n",
       "2                  8                5                1.6  ...  0  0  0  0   0   \n",
       "3                  2                5                0.4  ...  0  0  0  0   0   \n",
       "4                  0                5                0.0  ...  0  0  0  0   0   \n",
       "\n",
       "   11  12  13  14  15  \n",
       "0   0   0   0   0   0  \n",
       "1   0   0   0   0   0  \n",
       "2   0   0   0   0   0  \n",
       "3   0   0   0   0   0  \n",
       "4   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=range(2000,2019)\n",
    "num_years=5\n",
    "features=[\"count\",\"neighborCountyAvg\"]\n",
    "\n",
    "\n",
    "min_year=years[0]+num_years+1\n",
    "max_year=years[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features=features.copy()\n",
    "add_features.extend([\"year\",\"location\"])\n",
    "add_features.extend(i for i in range(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=cdc[add_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe for training data\n",
    "temporal_df=pd.DataFrame()                   #The final dataframe\n",
    "for year in range(max_year, min_year-1, -1): # loop from 2018 to 2002 with step of -1 in each round\n",
    "    col=\"A\"\n",
    "    yearly_df=pd.DataFrame()                 # created yearly_df empty dataframe\n",
    "    target=temp_df[temp_df[\"year\"]==year]    # created new df with name as target and calling on per year basis\n",
    "    classes=[i for i in range(1,16)]         # list of classes\n",
    "    target=target[classes]                   # target df updated with only that year classes\n",
    "    for prior_year in range(year-2,year-num_years-2,-1):  # loop from 2016 to 2014 with step of -1 in each round\n",
    "        df_prior_year=temp_df[temp_df[\"year\"]==prior_year]\n",
    "        for feature in features:\n",
    "            feat_values=list(df_prior_year[feature])\n",
    "            yearly_df[col]=feat_values\n",
    "            col=chr(ord(col)+1)              \n",
    "    yearly_df=pd.concat([yearly_df.reset_index(),target.reset_index()], axis=1).drop([\"index\"], axis=1)\n",
    "    temporal_df=temporal_df.append(yearly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe for testing data\n",
    "year=2020\n",
    "col=\"A\"\n",
    "temporal_df_test=pd.DataFrame()\n",
    "for prior_year in range(year-2,year-num_years-2,-1):\n",
    "    df_prior_year=temp_df[temp_df[\"year\"]==prior_year]\n",
    "    for feature in features:\n",
    "        feat_values=list(df_prior_year[feature])\n",
    "        temporal_df_test[col]=feat_values\n",
    "        col=chr(ord(col)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A         B  C    D  E         F  G         H  I         J  ...  6  7  8  \\\n",
       "0  1  0.000000  0  0.2  0  0.000000  0  0.000000  0  1.600000  ...  0  0  0   \n",
       "1  2  0.666667  0  1.0  0  0.333333  1  0.000000  4  3.000000  ...  0  0  0   \n",
       "2  0  0.000000  0  0.0  0  0.000000  0  0.000000  0  0.000000  ...  0  0  0   \n",
       "3  0  0.500000  1  0.0  0  0.000000  0  0.166667  0  1.166667  ...  0  0  0   \n",
       "4  0  0.333333  0  0.0  0  0.000000  0  0.000000  0  0.833333  ...  0  0  0   \n",
       "\n",
       "   9  10  11  12  13  14  15  \n",
       "0  0   0   0   0   0   0   0  \n",
       "1  0   0   0   0   0   0   0  \n",
       "2  0   0   0   0   0   0   0  \n",
       "3  0   0   0   0   0   0   0  \n",
       "4  0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 35220,\n",
       " 2: 4654,\n",
       " 3: 312,\n",
       " 4: 88,\n",
       " 5: 39,\n",
       " 6: 28,\n",
       " 7: 13,\n",
       " 8: 8,\n",
       " 9: 5,\n",
       " 10: 5,\n",
       " 11: 5,\n",
       " 12: 15,\n",
       " 13: 7,\n",
       " 14: 3,\n",
       " 15: 2}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking frequency of instances for each class\n",
    "dict_freq={}\n",
    "for i in range(1,16):\n",
    "    dict_freq[i]=len(temporal_df[temporal_df[i]==1])\n",
    "dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = temporal_df.iloc[:, 0:(num_years*len(features))]\n",
    "Y_pre = temporal_df.iloc[:, (num_years*len(features)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_pre.values\n",
    "Y=Y_pre.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Balancing the data w.r.t. class labels\n",
    "# ros = RandomOverSampler()\n",
    "# X, Y = ros.fit_resample(X_pre.values,Y_pre.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35220, 35220, 35220, 35220, 35220, 35220, 35220, 35220, 35220,\n",
       "       35220, 35220, 35220, 35220, 35220, 35220])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows all the class labels are now equally represented\n",
    "y=np.argmax(Y, axis=1)\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating classs weights based on their frequencies\n",
    "# y=np.argmax(temporal_df.iloc[:,-15:].values, axis=1)\n",
    "# class_weights=compute_class_weight(\"balanced\", [i for i in range(15)], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Implementation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization(input_shape=(num_years, len(features))))\n",
    "    network.add(Dense(4, activation=\"tanh\"))\n",
    "    network.add(GRU(15, dropout = 0.2, recurrent_dropout = 0.2, activation=\"tanh\"))\n",
    "    network.add(Dense(15, activation=\"softmax\"))\n",
    "    network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32323 samples, validate on 8081 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.5673 - accuracy: 0.8628 - val_loss: 0.4701 - val_accuracy: 0.8349\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.3821 - accuracy: 0.8814 - val_loss: 0.4558 - val_accuracy: 0.8349\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.3747 - accuracy: 0.8825 - val_loss: 0.4516 - val_accuracy: 0.8329\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3693 - accuracy: 0.8823 - val_loss: 0.4410 - val_accuracy: 0.8360\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.3689 - accuracy: 0.8825 - val_loss: 0.4401 - val_accuracy: 0.8337\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.3665 - accuracy: 0.8828 - val_loss: 0.4403 - val_accuracy: 0.8322\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.3667 - accuracy: 0.8827 - val_loss: 0.4407 - val_accuracy: 0.8312\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.3649 - accuracy: 0.8834 - val_loss: 0.4435 - val_accuracy: 0.8316\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.3634 - accuracy: 0.8832 - val_loss: 0.4374 - val_accuracy: 0.8317\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.3622 - accuracy: 0.8835 - val_loss: 0.4369 - val_accuracy: 0.8328\n",
      "Train on 32323 samples, validate on 8081 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.6244 - accuracy: 0.8402 - val_loss: 0.3927 - val_accuracy: 0.8729\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.4053 - accuracy: 0.8715 - val_loss: 0.3680 - val_accuracy: 0.8746\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.3953 - accuracy: 0.8717 - val_loss: 0.3686 - val_accuracy: 0.8729\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3901 - accuracy: 0.8728 - val_loss: 0.3714 - val_accuracy: 0.8728\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.3870 - accuracy: 0.8729 - val_loss: 0.3833 - val_accuracy: 0.8729\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.3875 - accuracy: 0.8727 - val_loss: 0.3583 - val_accuracy: 0.8730\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.3860 - accuracy: 0.8728 - val_loss: 0.3701 - val_accuracy: 0.8728\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.3862 - accuracy: 0.8727 - val_loss: 0.3645 - val_accuracy: 0.8759\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.3843 - accuracy: 0.8732 - val_loss: 0.3570 - val_accuracy: 0.8728\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.3839 - accuracy: 0.8733 - val_loss: 0.3680 - val_accuracy: 0.8729\n",
      "Train on 32323 samples, validate on 8081 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.5774 - accuracy: 0.8569 - val_loss: 0.4755 - val_accuracy: 0.8473\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.3844 - accuracy: 0.8787 - val_loss: 0.4622 - val_accuracy: 0.8490\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.3706 - accuracy: 0.8804 - val_loss: 0.4576 - val_accuracy: 0.8488\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3641 - accuracy: 0.8813 - val_loss: 0.4548 - val_accuracy: 0.8493\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.3651 - accuracy: 0.8801 - val_loss: 0.4489 - val_accuracy: 0.8487\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.3606 - accuracy: 0.8806 - val_loss: 0.4466 - val_accuracy: 0.8501\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.3611 - accuracy: 0.8805 - val_loss: 0.4478 - val_accuracy: 0.8493\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.3594 - accuracy: 0.8801 - val_loss: 0.4527 - val_accuracy: 0.8477\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.3591 - accuracy: 0.8809 - val_loss: 0.4505 - val_accuracy: 0.8489\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.3584 - accuracy: 0.8804 - val_loss: 0.4464 - val_accuracy: 0.8496\n",
      "Train on 32323 samples, validate on 8081 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.6442 - accuracy: 0.8324 - val_loss: 0.2550 - val_accuracy: 0.9411\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.4339 - accuracy: 0.8567 - val_loss: 0.2573 - val_accuracy: 0.9415\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.4231 - accuracy: 0.8576 - val_loss: 0.2915 - val_accuracy: 0.9400\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.4175 - accuracy: 0.8592 - val_loss: 0.2742 - val_accuracy: 0.9374\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.4141 - accuracy: 0.8590 - val_loss: 0.2815 - val_accuracy: 0.9396\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.4115 - accuracy: 0.8592 - val_loss: 0.2891 - val_accuracy: 0.9390\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.4114 - accuracy: 0.8590 - val_loss: 0.3114 - val_accuracy: 0.9371\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.4108 - accuracy: 0.8588 - val_loss: 0.3119 - val_accuracy: 0.9370\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.4097 - accuracy: 0.8592 - val_loss: 0.3272 - val_accuracy: 0.9386\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.4093 - accuracy: 0.8595 - val_loss: 0.3186 - val_accuracy: 0.9342\n",
      "Train on 32324 samples, validate on 8080 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.6052 - accuracy: 0.8448 - val_loss: 0.4156 - val_accuracy: 0.8686\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.3928 - accuracy: 0.8754 - val_loss: 0.4017 - val_accuracy: 0.8692\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.3839 - accuracy: 0.8746 - val_loss: 0.4013 - val_accuracy: 0.8681\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3790 - accuracy: 0.8745 - val_loss: 0.4021 - val_accuracy: 0.8689\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.3784 - accuracy: 0.8757 - val_loss: 0.3963 - val_accuracy: 0.8693\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.3763 - accuracy: 0.8766 - val_loss: 0.3982 - val_accuracy: 0.8699\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.3751 - accuracy: 0.8760 - val_loss: 0.4077 - val_accuracy: 0.8676\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.3749 - accuracy: 0.8767 - val_loss: 0.4035 - val_accuracy: 0.8679\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.3750 - accuracy: 0.8760 - val_loss: 0.4051 - val_accuracy: 0.8684\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.3730 - accuracy: 0.8763 - val_loss: 0.4048 - val_accuracy: 0.8651\n",
      "Training accuracy:0.87459785\n",
      "Validation accuracy:0.8709284782409668\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation setup\n",
    "acc_train=[]\n",
    "acc_val=[]\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, val_index in kf.split(X):   \n",
    "#     X_train=temporal_df.iloc[train_index,0:(num_years*len(features))]\n",
    "#     Y_train=temporal_df.iloc[train_index,(num_years*len(features)):]\n",
    "#     X_val=temporal_df.iloc[val_index,0:(num_years*len(features))]\n",
    "#     Y_val=temporal_df.iloc[val_index,(num_years*len(features)):]\n",
    "    X_train=X[train_index]\n",
    "    Y_train=Y[train_index]\n",
    "    X_val=X[val_index]\n",
    "    Y_val=Y[val_index]\n",
    "    \n",
    "    #Transforming input variables into LSTM input format\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "    X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "    Y_train=Y_train\n",
    "    Y_val=Y_val\n",
    "    \n",
    "    #Creating model\n",
    "    model=create_network()\n",
    "    Hist=model.fit(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), verbose=2, class_weight=None)\n",
    "    \n",
    "    #Final epoch accuraies for training and validation dataset\n",
    "    acc_train.append(Hist.history[\"accuracy\"][-1])\n",
    "    acc_val.append(Hist.history[\"val_accuracy\"][-1])\n",
    "    \n",
    "print(\"Training accuracy:\" + str(np.mean(acc_train)))\n",
    "print(\"Validation accuracy:\" + str(np.mean(acc_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset while using test_train split for final prediction\n",
    "\n",
    "#Transforming input variables into LSTM input format\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "Y_train=Y_train\n",
    "Y_val=Y_val\n",
    "\n",
    "X_test=temporal_df_test.iloc[:, 0:(num_years*len(features))]\n",
    "X_test = X_test.values.reshape(X_test.shape[0], num_years, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32323 samples, validate on 8081 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.5812 - accuracy: 0.8495 - val_loss: 0.3991 - val_accuracy: 0.8739\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.3961 - accuracy: 0.8726 - val_loss: 0.3858 - val_accuracy: 0.8746\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.3905 - accuracy: 0.8722 - val_loss: 0.3832 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.3851 - accuracy: 0.8735 - val_loss: 0.3826 - val_accuracy: 0.8743\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.3847 - accuracy: 0.8738 - val_loss: 0.3832 - val_accuracy: 0.8733\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.3817 - accuracy: 0.8733 - val_loss: 0.3801 - val_accuracy: 0.8741\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.3816 - accuracy: 0.8742 - val_loss: 0.3927 - val_accuracy: 0.8743\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.3820 - accuracy: 0.8740 - val_loss: 0.3839 - val_accuracy: 0.8745\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.3789 - accuracy: 0.8738 - val_loss: 0.3976 - val_accuracy: 0.8743\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.3788 - accuracy: 0.8738 - val_loss: 0.3957 - val_accuracy: 0.8748\n"
     ]
    }
   ],
   "source": [
    "Hist=model.fit(X_train, Y_train, nb_epoch=10, validation_data=(X_val, Y_val), verbose=2, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting value for train, val, and test datasets\n",
    "pred_train=model.predict(X_train)\n",
    "pred_val=model.predict(X_val)\n",
    "pred_test=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting probabilities to class labels\n",
    "pred_train_class=np.argmax(pred_train, axis=1)+1\n",
    "pred_train_class=list(map(lambda x: str(x), pred_train_class))\n",
    "pred_val_class=np.argmax(pred_val, axis=1)+1\n",
    "pred_val_class=list(map(lambda x: str(x), pred_val_class))\n",
    "pred_test_class=np.argmax(pred_test, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train_class=np.argmax(Y_train, axis=1)+1\n",
    "true_train_class=list(map(lambda x: str(x), true_train_class))\n",
    "true_val_class=np.argmax(Y_val, axis=1)+1\n",
    "true_val_class=list(map(lambda x: str(x), true_val_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i) for i in range(1,16)]\n",
    "cm_train = confusion_matrix(true_train_class, pred_train_class , labels)\n",
    "#cm_train=cm_train.astype('float') / cm_train.sum(axis=1)[:, np.newaxis] #For normalizing\n",
    "cm_val = confusion_matrix(true_val_class, pred_val_class , labels)\n",
    "#cm_val=cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis] #For normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1     2     3     4     5     6     7     8     9    10    11    12    13    14    15 \n",
      "        1 28089.0  85.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        2 3542.0 179.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        3 181.0  71.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        4  36.0  35.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        5  16.0  15.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        6  13.0   9.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        7   7.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        8   5.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        9   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       10   1.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       11   0.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       12   4.0  10.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       13   1.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       14   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       15   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(cm_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1     2     3     4     5     6     7     8     9    10    11    12    13    14    15 \n",
      "        1 7025.0  21.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        2 889.0  44.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        3  45.0  15.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        4   8.0   9.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        5   7.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        6   2.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        7   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        8   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        9   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       10   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       11   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       12   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       13   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       14   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       15   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(cm_val, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      1.00      0.93      7046\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "           2       0.44      0.05      0.09       933\n",
      "           3       0.00      0.00      0.00        60\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87      8081\n",
      "   macro avg       0.09      0.07      0.07      8081\n",
      "weighted avg       0.82      0.87      0.83      8081\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Evaluation metrics for valdation dataset\n",
    "print(metrics.classification_report(true_val_class, pred_val_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Implementation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization(input_shape=(num_years, len(features))))\n",
    "    network.add(Dense(4, activation=\"tanh\"))\n",
    "    network.add(LSTM(15, dropout = 0.2, recurrent_dropout = 0.2, activation=\"tanh\"))\n",
    "    network.add(Dense(1, activation=\"tanh\"))\n",
    "    network.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12432 samples, validate on 12432 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.7554 - accuracy: 0.8436 - val_loss: 0.4844 - val_accuracy: 0.8439\n",
      "Train on 12432 samples, validate on 12432 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.7612 - accuracy: 0.8254 - val_loss: 0.4337 - val_accuracy: 0.8642\n",
      "Training accuracy:0.8344997\n",
      "Validation accuracy:0.8540459871292114\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation setup\n",
    "acc_train=[]\n",
    "acc_val=[]\n",
    "kf = KFold(n_splits=2)\n",
    "for train_index, val_index in kf.split(temporal_df):   \n",
    "    X_train=temporal_df.iloc[train_index,0:(num_years*len(features))]\n",
    "    Y_train=temporal_df.iloc[train_index,(num_years*len(features)):]\n",
    "    X_val=temporal_df.iloc[val_index,0:(num_years*len(features))]\n",
    "    Y_val=temporal_df.iloc[val_index,(num_years*len(features)):]\n",
    "    \n",
    "    #Transforming input variables into LSTM input format\n",
    "    X_train = X_train.values.reshape(X_train.shape[0], num_years, len(features))\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], num_years, len(features))\n",
    "    Y_train=Y_train.values\n",
    "    Y_val=Y_val.values\n",
    "    \n",
    "    #Creating model\n",
    "    model=create_network()\n",
    "    Hist=model.fit(X_train, Y_train, epochs=1, validation_data=(X_val, Y_val), verbose=2)\n",
    "    \n",
    "    #Final epoch accuracies for training and validation dataset\n",
    "    acc_train.append(Hist.history[\"accuracy\"][-1])\n",
    "    acc_val.append(Hist.history[\"val_accuracy\"][-1])\n",
    "    \n",
    "print(\"Training accuracy:\" + str(np.mean(acc_train)))\n",
    "print(\"Validation accuracy:\" + str(np.mean(acc_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.82e-02, 5.04e-01, 7.47e+00, 2.81e+01, 6.63e+01, 8.72e+01,\n",
       "       2.37e+02, 2.37e+02, 8.29e+02, 4.14e+02, 5.53e+02, 1.51e+02,\n",
       "       2.76e+02, 5.53e+02, 8.29e+02])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 2s - loss: 1.3761 - accuracy: 0.8402\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.5475 - accuracy: 0.8655\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.4853 - accuracy: 0.8655\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.4663 - accuracy: 0.8655\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.4594 - accuracy: 0.8655\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.4565 - accuracy: 0.8655\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.4539 - accuracy: 0.8655\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.4541 - accuracy: 0.8651\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.4518 - accuracy: 0.8644\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.4490 - accuracy: 0.8652\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.4493 - accuracy: 0.8652\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.4468 - accuracy: 0.8648\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.4440 - accuracy: 0.8658\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.4433 - accuracy: 0.8657\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.4426 - accuracy: 0.8649\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.4406 - accuracy: 0.8669\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.4400 - accuracy: 0.8659\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.4394 - accuracy: 0.8652\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.4374 - accuracy: 0.8659\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.4366 - accuracy: 0.8665\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.4388 - accuracy: 0.8644\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.4358 - accuracy: 0.8659\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.4341 - accuracy: 0.8658\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.4333 - accuracy: 0.8657\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.4346 - accuracy: 0.8653\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.4331 - accuracy: 0.8652\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.4317 - accuracy: 0.8652\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.4319 - accuracy: 0.8665\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.4310 - accuracy: 0.8650\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.4302 - accuracy: 0.8650\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.4294 - accuracy: 0.8652\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.4305 - accuracy: 0.8652\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.4292 - accuracy: 0.8647\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.4285 - accuracy: 0.8657\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8655\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.4293 - accuracy: 0.8648\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8645\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.4272 - accuracy: 0.8656\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8652\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.4283 - accuracy: 0.8650\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.4262 - accuracy: 0.8660\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.4279 - accuracy: 0.8643\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.4278 - accuracy: 0.8652\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.4272 - accuracy: 0.8651\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.4275 - accuracy: 0.8650\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.4273 - accuracy: 0.8657\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8647\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.4268 - accuracy: 0.8644\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8646\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.4254 - accuracy: 0.8655\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.4271 - accuracy: 0.8636\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.4262 - accuracy: 0.8652\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.4266 - accuracy: 0.8653\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.4267 - accuracy: 0.8651\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.4265 - accuracy: 0.8645\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8653\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.4261 - accuracy: 0.8650\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8651\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8649\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8653\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8655\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.4264 - accuracy: 0.8647\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.4260 - accuracy: 0.8648\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8650\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8657\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.4266 - accuracy: 0.8646\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8648\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8656\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8649\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8654\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8648\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.4244 - accuracy: 0.8654\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.4252 - accuracy: 0.8658\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8649\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8636\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8648\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8655\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8652\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8650\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8641\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.4247 - accuracy: 0.8645\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8639\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.4256 - accuracy: 0.8641\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8654\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8658\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8645\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8641\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.4260 - accuracy: 0.8646\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.4256 - accuracy: 0.8650\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.4256 - accuracy: 0.8646\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8653\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8650\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8653\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8653\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.4244 - accuracy: 0.8654\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8656\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.4248 - accuracy: 0.8651\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.4242 - accuracy: 0.8648\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.4247 - accuracy: 0.8652\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8652\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.4244 - accuracy: 0.8639\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8659\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.4243 - accuracy: 0.8653\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8647\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8656\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8649\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.4252 - accuracy: 0.8651\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8645\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8655\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8639\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8650\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8651\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8648\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8638\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.4238 - accuracy: 0.8645\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8648\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.4259 - accuracy: 0.8647\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.4243 - accuracy: 0.8650\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8643\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8645\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8652\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8652\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8648\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8655\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8648\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8648\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.4240 - accuracy: 0.8654\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-689ecda38a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_network, epochs=200, batch_size=64, verbose=2)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# network.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization())\n",
    "    network.add(Dense(3000, activation=\"relu\", input_shape=(39782,)))\n",
    "    network.add(Dense(1500, activation=\"relu\"))\n",
    "    network.add(Dense(300, activation=\"relu\"))\n",
    "    network.add(Dense(15, activation=\"softmax\"))\n",
    "\n",
    "    network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 30s - loss: 0.4627 - accuracy: 0.8632\n",
      "Epoch 2/8\n",
      " - 30s - loss: 0.4319 - accuracy: 0.8668\n",
      "Epoch 3/8\n",
      " - 30s - loss: 0.4278 - accuracy: 0.8664\n",
      "Epoch 4/8\n",
      " - 30s - loss: 0.4261 - accuracy: 0.8661\n",
      "Epoch 5/8\n",
      " - 30s - loss: 0.4256 - accuracy: 0.8661\n",
      "Epoch 6/8\n",
      " - 31s - loss: 0.4247 - accuracy: 0.8668\n",
      "Epoch 7/8\n",
      " - 32s - loss: 0.4238 - accuracy: 0.8667\n",
      "Epoch 8/8\n",
      " - 30s - loss: 0.4224 - accuracy: 0.8676\n",
      "Epoch 1/8\n",
      " - 33s - loss: 0.4635 - accuracy: 0.8644\n",
      "Epoch 2/8\n",
      " - 31s - loss: 0.4290 - accuracy: 0.8678\n",
      "Epoch 3/8\n",
      " - 30s - loss: 0.4253 - accuracy: 0.8676\n",
      "Epoch 4/8\n",
      " - 31s - loss: 0.4237 - accuracy: 0.8675\n",
      "Epoch 5/8\n",
      " - 31s - loss: 0.4218 - accuracy: 0.8678\n",
      "Epoch 6/8\n",
      " - 30s - loss: 0.4206 - accuracy: 0.8689\n",
      "Epoch 7/8\n",
      " - 30s - loss: 0.4200 - accuracy: 0.8682\n",
      "Epoch 8/8\n",
      " - 30s - loss: 0.4201 - accuracy: 0.8687\n",
      "Epoch 1/8\n",
      " - 31s - loss: 0.4646 - accuracy: 0.8620\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4312 - accuracy: 0.8659\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4283 - accuracy: 0.8667\n",
      "Epoch 4/8\n",
      " - 30s - loss: 0.4257 - accuracy: 0.8667\n",
      "Epoch 5/8\n",
      " - 31s - loss: 0.4258 - accuracy: 0.8668\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.4247 - accuracy: 0.8663\n",
      "Epoch 7/8\n",
      " - 29s - loss: 0.4244 - accuracy: 0.8661\n",
      "Epoch 8/8\n",
      " - 29s - loss: 0.4230 - accuracy: 0.8667\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4605 - accuracy: 0.8643\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4293 - accuracy: 0.8672\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4269 - accuracy: 0.8679\n",
      "Epoch 4/8\n",
      " - 29s - loss: 0.4247 - accuracy: 0.8676\n",
      "Epoch 5/8\n",
      " - 29s - loss: 0.4240 - accuracy: 0.8677\n",
      "Epoch 6/8\n",
      " - 29s - loss: 0.4228 - accuracy: 0.8671\n",
      "Epoch 7/8\n",
      " - 28s - loss: 0.4222 - accuracy: 0.8671\n",
      "Epoch 8/8\n",
      " - 29s - loss: 0.4221 - accuracy: 0.8683\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4625 - accuracy: 0.8633\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4319 - accuracy: 0.8665\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4278 - accuracy: 0.8660\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.4252 - accuracy: 0.8673\n",
      "Epoch 5/8\n",
      " - 29s - loss: 0.4248 - accuracy: 0.8668\n",
      "Epoch 6/8\n",
      " - 29s - loss: 0.4248 - accuracy: 0.8667\n",
      "Epoch 7/8\n",
      " - 28s - loss: 0.4235 - accuracy: 0.8667\n",
      "Epoch 8/8\n",
      " - 28s - loss: 0.4229 - accuracy: 0.8663\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4600 - accuracy: 0.8628\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4318 - accuracy: 0.8662\n",
      "Epoch 3/8\n",
      " - 28s - loss: 0.4271 - accuracy: 0.8664\n",
      "Epoch 4/8\n",
      " - 29s - loss: 0.4273 - accuracy: 0.8663\n",
      "Epoch 5/8\n",
      " - 29s - loss: 0.4250 - accuracy: 0.8662\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.4244 - accuracy: 0.8666\n",
      "Epoch 7/8\n",
      " - 28s - loss: 0.4237 - accuracy: 0.8667\n",
      "Epoch 8/8\n",
      " - 28s - loss: 0.4232 - accuracy: 0.8669\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4553 - accuracy: 0.8661\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4249 - accuracy: 0.8686\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4227 - accuracy: 0.8681\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.4215 - accuracy: 0.8689\n",
      "Epoch 5/8\n",
      " - 28s - loss: 0.4203 - accuracy: 0.8680\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.4186 - accuracy: 0.8686\n",
      "Epoch 7/8\n",
      " - 29s - loss: 0.4191 - accuracy: 0.8688\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4165 - accuracy: 0.8695\n",
      "Epoch 1/8\n",
      " - 42s - loss: 0.4605 - accuracy: 0.8626\n",
      "Epoch 2/8\n",
      " - 37s - loss: 0.4303 - accuracy: 0.8664\n",
      "Epoch 3/8\n",
      " - 37s - loss: 0.4270 - accuracy: 0.8668\n",
      "Epoch 4/8\n",
      " - 36s - loss: 0.4251 - accuracy: 0.8668\n",
      "Epoch 5/8\n",
      " - 37s - loss: 0.4226 - accuracy: 0.8676\n",
      "Epoch 6/8\n",
      " - 37s - loss: 0.4229 - accuracy: 0.8672\n",
      "Epoch 7/8\n",
      " - 38s - loss: 0.4209 - accuracy: 0.8675\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4200 - accuracy: 0.8664\n",
      "Epoch 1/8\n",
      " - 39s - loss: 0.4612 - accuracy: 0.8648\n",
      "Epoch 2/8\n",
      " - 37s - loss: 0.4321 - accuracy: 0.8671\n",
      "Epoch 3/8\n",
      " - 37s - loss: 0.4256 - accuracy: 0.8663\n",
      "Epoch 4/8\n",
      " - 37s - loss: 0.4250 - accuracy: 0.8673\n",
      "Epoch 5/8\n",
      " - 37s - loss: 0.4249 - accuracy: 0.8674\n",
      "Epoch 6/8\n",
      " - 37s - loss: 0.4230 - accuracy: 0.8676\n",
      "Epoch 7/8\n",
      " - 37s - loss: 0.4214 - accuracy: 0.8672\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4227 - accuracy: 0.8668\n",
      "Epoch 1/8\n",
      " - 39s - loss: 0.4653 - accuracy: 0.8635\n",
      "Epoch 2/8\n",
      " - 37s - loss: 0.4296 - accuracy: 0.8666\n",
      "Epoch 3/8\n",
      " - 37s - loss: 0.4269 - accuracy: 0.8671\n",
      "Epoch 4/8\n",
      " - 37s - loss: 0.4245 - accuracy: 0.8669\n",
      "Epoch 5/8\n",
      " - 37s - loss: 0.4248 - accuracy: 0.8678\n",
      "Epoch 6/8\n",
      " - 37s - loss: 0.4240 - accuracy: 0.8671\n",
      "Epoch 7/8\n",
      " - 37s - loss: 0.4222 - accuracy: 0.8676\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4216 - accuracy: 0.8677\n",
      "Baseline: 86.56% (0.69%)\n"
     ]
    }
   ],
   "source": [
    "X = temporal_df.iloc[:, 0:4].values\n",
    "Y = temporal_df.iloc[:, 4:].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_network, epochs=8, batch_size=64, verbose=2)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.56% (0.686%)\n"
     ]
    }
   ],
   "source": [
    "# This is a reasonable estimation of the performance of the model on unseen data.\n",
    "\n",
    "print('Accuracy: %.2f%% (%.3f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39782 samples, validate on 9946 samples\n",
      "Epoch 1/8\n",
      " - 74s - loss: 0.4495 - accuracy: 0.8642 - val_loss: 0.4511 - val_accuracy: 0.8674\n",
      "Epoch 2/8\n",
      " - 69s - loss: 0.4313 - accuracy: 0.8647 - val_loss: 0.4353 - val_accuracy: 0.8682\n",
      "Epoch 3/8\n",
      " - 69s - loss: 0.4274 - accuracy: 0.8667 - val_loss: 0.4306 - val_accuracy: 0.8678\n",
      "Epoch 4/8\n",
      " - 72s - loss: 0.4258 - accuracy: 0.8660 - val_loss: 0.4265 - val_accuracy: 0.8678\n",
      "Epoch 5/8\n",
      " - 70s - loss: 0.4262 - accuracy: 0.8662 - val_loss: 0.4274 - val_accuracy: 0.8688\n",
      "Epoch 6/8\n",
      " - 71s - loss: 0.4253 - accuracy: 0.8664 - val_loss: 0.4248 - val_accuracy: 0.8680\n",
      "Epoch 7/8\n",
      " - 71s - loss: 0.4231 - accuracy: 0.8665 - val_loss: 0.4242 - val_accuracy: 0.8680\n",
      "Epoch 8/8\n",
      " - 70s - loss: 0.4229 - accuracy: 0.8670 - val_loss: 0.4302 - val_accuracy: 0.8668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2157ea7d8d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = create_network()\n",
    "network.fit(X_train, Y_train, epochs=8, validation_data=(X_test, Y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9946/9946 [==============================] - 2s 237us/step\n"
     ]
    }
   ],
   "source": [
    "results2 = network.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.68% \n",
      "Loss: 0.430\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f%% \\nLoss: %.3f' % (results2[1]*100, results2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = network.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = pd.DataFrame(Y_pred_test)\n",
    "Y_pred_test = Y_pred_test.T\n",
    "for i in Y_pred_test.columns.tolist():\n",
    "    Y_pred_test[i] = np.where(Y_pred_test[i] == max(Y_pred_test[i]), 1, 0)\n",
    "\n",
    "Y_pred_test = Y_pred_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
       "0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "5   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "6   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "7   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "8   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "9   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
       "0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "5   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "6   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "7   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "8   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "9   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = pd.DataFrame(Y_test)\n",
    "Y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
