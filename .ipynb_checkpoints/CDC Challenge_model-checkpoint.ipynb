{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import itertools  \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "#years=range(2000,2019)\n",
    "years=range(2000,2010)\n",
    "num_years=2\n",
    "#Features/columns that will be used for prediction.\n",
    "features=[\"count\",\"neighborCountyAvg\", \"Gini\", \"Temp\", \"Prec\", \"Hum\", \"County_type\", \"Resident_population_White_alone_percent\", \"Median_Household_Income\", \"Poverty_percent_of_people\"]\n",
    "#features=[\"count\",\"neighborCountyAvg\", \"Gini\", \"Temp\", \"Prec\", \"Hum\", \"County_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading the data with State Avg column\n",
    "\n",
    "# path_data=\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/WNV_challenge_neighCountyAvg.csv\"\n",
    "# data=pd.read_csv(path_data)\n",
    "\n",
    "# #Changes/Cleaning that needs to be done in data as mentioned by the cdc manual\n",
    "\n",
    "# data['county'] = np.where(data['county']=='Bedford/Bedford City', 'Bedford', data['county'])\n",
    "# data['fips'] = np.where(data['fips']=='51019/51515', '51019', data['fips'])\n",
    "# data['location'] = np.where(data['location']=='Virginia-Bedford/Bedford City', 'Virginia-Bedford', data['location'])\n",
    "\n",
    "# data['county'] = np.where(data['county']=='Oglala Lakota/Shannon', 'Oglala Lakota', data['county'])\n",
    "# data['fips'] = np.where(data['fips']=='46102/46113', '46102', data['fips'])\n",
    "# data['location'] = np.where(data['location']=='South Dakota-Oglala Lakota/Shannon', 'South Dakota-Oglala Lakota', data['location'])\n",
    "\n",
    "# #converting fips from object/string to int datatype\n",
    "\n",
    "# data['fips']=data['fips'].apply(pd.to_numeric)\n",
    "# data.rename(columns={'fips':'GEOID'}, inplace=True)\n",
    "\n",
    "# bin_dummy={1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[], 10:[], 11:[], 12:[], 13:[], 14:[], 15:[]}\n",
    "\n",
    "# for i in range(len(data)):\n",
    "#     cl=data.iloc[i][\"bin\"]\n",
    "#     for j in bin_dummy:\n",
    "#         bin_dummy[j].append(0)\n",
    "#     bin_dummy[cl][-1]=1\n",
    "    \n",
    "# for i in bin_dummy:\n",
    "#     data[i]=bin_dummy[i]\n",
    "    \n",
    "# path_data_var=\"/Users/sparshagarwal/Downloads/NARR_weather_data/weekly_precipitation_gini.csv\"\n",
    "# data_var=pd.read_csv(path_data_var)\n",
    "\n",
    "# gini=[]\n",
    "# temp=data[data[\"year\"]==2000]\n",
    "# for i in range(len(temp)):\n",
    "#     geoid=temp.iloc[i][\"GEOID\"]\n",
    "#     gini.extend(data_var[data_var[\"GEOID\"]==geoid].values[0][1:])\n",
    "# data[\"Gini\"]=gini\n",
    "\n",
    "\n",
    "# #Adding air, precipitation and humidity data.\n",
    "# #Defining number of days in each year\n",
    "# days_dict={}\n",
    "# for year in years:\n",
    "#     days=365\n",
    "#     if(year%4==0):\n",
    "#         days=366\n",
    "#     days_dict[year]=days\n",
    "    \n",
    "# #Taking the average values of the variables across a single year\n",
    "# df_temp=pd.DataFrame()\n",
    "# df_prec=pd.DataFrame()\n",
    "# df_hum=pd.DataFrame()\n",
    "\n",
    "# variables=[\"Temp\",\"Prec\",\"Hum\"]\n",
    "\n",
    "# for var in variables:\n",
    "#     value=[]\n",
    "#     if(var==\"Temp\"):\n",
    "#         path_data_var=\"/Users/sparshagarwal/Downloads/NARR_weather_data/air.sfc_complete.csv\"\n",
    "#     if(var==\"Prec\"):\n",
    "#         path_data_var=\"/Users/sparshagarwal/Downloads/NARR_weather_data/apcp_complete.csv\"\n",
    "#     if(var==\"Hum\"):\n",
    "#         path_data_var=\"/Users/sparshagarwal/Downloads/NARR_weather_data/rhum.2m_complete.csv\"\n",
    "#     data_var=pd.read_csv(path_data_var)\n",
    "    \n",
    "#     year_col=[]\n",
    "#     geoid_col=[]\n",
    "#     for i in range(len(data_var)):\n",
    "#         print(i)\n",
    "#         count=1\n",
    "#         for year in years:\n",
    "#             geoid_col.append(data_var.iloc[i][0])\n",
    "#             year_col.append(year)\n",
    "#             days=days_dict[year]\n",
    "    \n",
    "#             avg=np.mean(list(data_var.iloc[i][count:count+days]))\n",
    "#             value.append(avg)\n",
    "            \n",
    "#             count+=days\n",
    "    \n",
    "#     if(var==\"Temp\"):\n",
    "#         df_temp[\"GEOID\"]=geoid_col\n",
    "#         df_temp[\"year\"]=year_col\n",
    "#         df_temp[\"Temp\"]=value\n",
    "        \n",
    "#     if(var==\"Prec\"):\n",
    "#         df_prec[\"GEOID\"]=geoid_col\n",
    "#         df_prec[\"year\"]=year_col\n",
    "#         df_prec[\"Prec\"]=value\n",
    "        \n",
    "#     if(var==\"Hum\"):\n",
    "#         df_hum[\"GEOID\"]=geoid_col\n",
    "#         df_hum[\"year\"]=year_col\n",
    "#         df_hum[\"Hum\"]=value\n",
    "        \n",
    "\n",
    "# #Merging all the dataframe together\n",
    "# variables=[\"Temp\",\"Prec\",\"Hum\"]\n",
    "# for var in variables:\n",
    "#     if(var==\"Temp\"):\n",
    "#         df_c=df_temp.copy()\n",
    "#     if(var==\"Prec\"):\n",
    "#         df_c=df_prec.copy()\n",
    "#     if(var==\"Hum\"):\n",
    "#         df_c=df_hum.copy()\n",
    "        \n",
    "#     data=pd.merge(data, df_c,  how='inner', left_on=['GEOID','year'], right_on = ['GEOID','year'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Adding socioeconomic data for 10 years\n",
    "# variables=[\"Resident_population_White_alone_percent\", \"Median_Household_Income\", \"Poverty_percent_of_people\"]\n",
    "# for variable in variables:\n",
    "#     if(variable==\"Poverty_percent_of_people\" or variable==\"Median_Household_Income\"):\n",
    "#         data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/se_data.csv\"\n",
    "#         s_years=range(1999, 2010)\n",
    "#     if(variable==\"Resident_population_White_alone_percent\"):\n",
    "#         data_path=\"/Users/sparshagarwal/Downloads/WMV_data/Socioeconomics/race_data.csv\"\n",
    "#         s_years=range(2000, 2010)\n",
    "#     # Adding data for the variable\n",
    "#     s_data=pd.read_csv(data_path)\n",
    "#     s_data.rename(columns={'STCOU':'GEOID', 'YEAR':'year'}, inplace=True)\n",
    "#     s_data=s_data[s_data[\"GEOID\"]!=0]\n",
    "#     s_data=s_data[s_data[\"year\"]>=2000]\n",
    "#     s_data=s_data[[\"year\", \"GEOID\", variable]]\n",
    "#     data=pd.merge(data, s_data,  how='inner', left_on=['GEOID','year'], right_on = ['GEOID','year'])\n",
    "\n",
    "# #Minimum and maximum value of years that will form the target class\n",
    "# min_year=years[0]+num_years+1\n",
    "# max_year=years[-1]\n",
    "\n",
    "# add_features=features.copy()\n",
    "# add_features.extend([\"year\",\"location\"])\n",
    "# add_features.extend(i for i in range(1,16))\n",
    "\n",
    "# temp_df=data[add_features]\n",
    "\n",
    "# #Removing the rows having NaN Gini index values\n",
    "# temp_df=temp_df[temp_df.isnull()[\"Gini\"]==False]\n",
    "\n",
    "# #Creating dataframe for training data\n",
    "# temporal_df=pd.DataFrame() #The final dataframe\n",
    "# for year in range(max_year,min_year-1,-1):\n",
    "#     col=\"A\"\n",
    "#     yearly_df=pd.DataFrame()\n",
    "#     target=temp_df[temp_df[\"year\"]==year]\n",
    "#     classes=[i for i in range(1,16)]\n",
    "#     target=target[classes]\n",
    "#     for prior_year in range(year-2,year-num_years-2,-1):\n",
    "#         df_prior_year=temp_df[temp_df[\"year\"]==prior_year]\n",
    "#         for feature in features:\n",
    "#             feat_values=list(df_prior_year[feature])\n",
    "#             yearly_df[col]=feat_values\n",
    "#             col=chr(ord(col)+1)\n",
    "#     yearly_df=pd.concat([yearly_df.reset_index(),target.reset_index()], axis=1).drop([\"index\"], axis=1)\n",
    "#     temporal_df=temporal_df.append(yearly_df)\n",
    "    \n",
    "# #Creating dataframe for testing data\n",
    "# year=2020\n",
    "# col=\"A\"\n",
    "# temporal_df_test=pd.DataFrame()\n",
    "# for prior_year in range(year-2,year-num_years-2,-1):\n",
    "#     df_prior_year=temp_df[temp_df[\"year\"]==prior_year]\n",
    "#     for feature in features:\n",
    "#         feat_values=list(df_prior_year[feature])\n",
    "#         temporal_df_test[col]=feat_values\n",
    "#         col=chr(ord(col)+1)\n",
    "        \n",
    "# temporal_df.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Temporal_df.csv\", index=False)\n",
    "# temporal_df_test.to_csv(\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Temporal_df_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing training and testing data\n",
    "train_path=\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Temporal_df.csv\"\n",
    "temporal_df=pd.read_csv(train_path)\n",
    "test_path=\"/Users/sparshagarwal/Desktop/NCSA/Dataframes/Temporal_df_test.csv\"\n",
    "temporal_df_test=pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>293.287243</td>\n",
       "      <td>2.213271</td>\n",
       "      <td>67.009978</td>\n",
       "      <td>1</td>\n",
       "      <td>79.9</td>\n",
       "      <td>50375</td>\n",
       "      <td>10.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.537571</td>\n",
       "      <td>294.120045</td>\n",
       "      <td>3.282847</td>\n",
       "      <td>73.206087</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>49163</td>\n",
       "      <td>10.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.533643</td>\n",
       "      <td>293.707240</td>\n",
       "      <td>2.828810</td>\n",
       "      <td>68.827561</td>\n",
       "      <td>0</td>\n",
       "      <td>51.9</td>\n",
       "      <td>30370</td>\n",
       "      <td>26.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518810</td>\n",
       "      <td>293.187767</td>\n",
       "      <td>2.066242</td>\n",
       "      <td>66.867036</td>\n",
       "      <td>0</td>\n",
       "      <td>76.8</td>\n",
       "      <td>38907</td>\n",
       "      <td>18.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.515222</td>\n",
       "      <td>292.072319</td>\n",
       "      <td>1.964871</td>\n",
       "      <td>63.962782</td>\n",
       "      <td>0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>43266</td>\n",
       "      <td>13.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A         B         C           D         E          F  G     H      I  \\\n",
       "0  0  2.200000  0.524172  293.287243  2.213271  67.009978  1  79.9  50375   \n",
       "1  0  0.166667  0.537571  294.120045  3.282847  73.206087  1  88.0  49163   \n",
       "2  0  0.125000  0.533643  293.707240  2.828810  68.827561  0  51.9  30370   \n",
       "3  0  0.000000  0.518810  293.187767  2.066242  66.867036  0  76.8  38907   \n",
       "4  0  0.166667  0.515222  292.072319  1.964871  63.962782  0  96.4  43266   \n",
       "\n",
       "      J  ...  6  7  8  9  10  11  12  13  14  15  \n",
       "0  10.4  ...  0  0  0  0   0   0   0   0   0   0  \n",
       "1  10.3  ...  0  0  0  0   0   0   0   0   0   0  \n",
       "2  26.1  ...  0  0  0  0   0   0   0   0   0   0  \n",
       "3  18.2  ...  0  0  0  0   0   0   0   0   0   0  \n",
       "4  13.1  ...  0  0  0  0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 18857,\n",
       " 2: 2536,\n",
       " 3: 170,\n",
       " 4: 54,\n",
       " 5: 28,\n",
       " 6: 19,\n",
       " 7: 13,\n",
       " 8: 4,\n",
       " 9: 4,\n",
       " 10: 2,\n",
       " 11: 6,\n",
       " 12: 10,\n",
       " 13: 3,\n",
       " 14: 1,\n",
       " 15: 0}"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking frequency of instances for each class\n",
    "dict_freq={}\n",
    "for i in range(1,16):\n",
    "    dict_freq[i]=len(temporal_df[temporal_df[str(i)]==1])\n",
    "dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling to balance the classes\n",
    "num_cl=len(temporal_df[temporal_df[\"1\"]==1])\n",
    "df_balanced=temporal_df[temporal_df[\"1\"]==1]\n",
    "for i in range(2,16):\n",
    "    df_temp=temporal_df[temporal_df[str(i)]==1]\n",
    "    if(len(df_temp)>0):\n",
    "        df_minority_upsampled = resample(df_temp, replace=True, n_samples=num_cl, random_state=4)\n",
    "        df_balanced=pd.concat([df_balanced, df_minority_upsampled])\n",
    "df_balanced = df_balanced.sample(frac = 1, random_state=4)   #Shuffling the data\n",
    "X_pre = df_balanced.iloc[:, 0:(num_years*len(features))]\n",
    "Y_pre = df_balanced.iloc[:, (num_years*len(features)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using unbalanced data\n",
    "# temporal_df = temporal_df.sample(frac = 1) #Shuffling the data\n",
    "# X_pre = temporal_df.iloc[:, 0:(num_years*len(features))]\n",
    "# Y_pre = temporal_df.iloc[:, (num_years*len(features)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_pre.values\n",
    "Y=Y_pre.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Balancing the data w.r.t. class labels\n",
    "# ros = RandomOverSampler()\n",
    "# X, Y = ros.fit_resample(X_pre.values,Y_pre.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18857, 18857, 18857, 18857, 18857, 18857, 18857, 18857, 18857,\n",
       "       18857, 18857, 18857, 18857, 18857])"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows all the class labels are now equally represented\n",
    "y=np.argmax(Y, axis=1)\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating classs weights based on their frequencies\n",
    "# y=np.argmax(temporal_df.iloc[:,-15:].values, axis=1)\n",
    "# class_weights=compute_class_weight(\"balanced\", [i for i in range(15)], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Implementation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization(input_shape=(num_years, len(features))))\n",
    "    network.add(Dense(4, activation=\"tanh\"))\n",
    "    network.add(LSTM(15, dropout = 0.2, recurrent_dropout = 0.2, activation=\"tanh\"))\n",
    "    network.add(Dense(15, activation=\"softmax\"))\n",
    "    network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 515040 samples, validate on 128760 samples\n",
      "Epoch 1/10\n",
      " - 38s - loss: 1.9470 - accuracy: 0.3398 - val_loss: 1.4238 - val_accuracy: 0.5425\n",
      "Epoch 2/10\n",
      " - 34s - loss: 1.6535 - accuracy: 0.4465 - val_loss: 1.2079 - val_accuracy: 0.6114\n",
      "Epoch 3/10\n",
      " - 33s - loss: 1.5637 - accuracy: 0.4749 - val_loss: 1.1251 - val_accuracy: 0.6133\n",
      "Epoch 4/10\n",
      " - 34s - loss: 1.5201 - accuracy: 0.4892 - val_loss: 1.0843 - val_accuracy: 0.6371\n",
      "Epoch 5/10\n",
      " - 34s - loss: 1.4924 - accuracy: 0.4973 - val_loss: 1.0562 - val_accuracy: 0.6531\n",
      "Epoch 6/10\n",
      " - 34s - loss: 1.4764 - accuracy: 0.5027 - val_loss: 1.0330 - val_accuracy: 0.6492\n",
      "Epoch 7/10\n",
      " - 35s - loss: 1.4614 - accuracy: 0.5072 - val_loss: 1.0133 - val_accuracy: 0.6614\n",
      "Epoch 8/10\n",
      " - 33s - loss: 1.4480 - accuracy: 0.5114 - val_loss: 1.0021 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      " - 33s - loss: 1.4446 - accuracy: 0.5128 - val_loss: 1.0074 - val_accuracy: 0.6608\n",
      "Epoch 10/10\n",
      " - 33s - loss: 1.4303 - accuracy: 0.5177 - val_loss: 0.9904 - val_accuracy: 0.6749\n",
      "Train on 515040 samples, validate on 128760 samples\n",
      "Epoch 1/10\n",
      " - 33s - loss: 2.0033 - accuracy: 0.3150 - val_loss: 1.5056 - val_accuracy: 0.5085\n",
      "Epoch 2/10\n",
      " - 34s - loss: 1.7164 - accuracy: 0.4165 - val_loss: 1.3255 - val_accuracy: 0.5455\n",
      "Epoch 3/10\n",
      " - 34s - loss: 1.6105 - accuracy: 0.4535 - val_loss: 1.2251 - val_accuracy: 0.5793\n",
      "Epoch 4/10\n",
      " - 33s - loss: 1.5566 - accuracy: 0.4730 - val_loss: 1.1585 - val_accuracy: 0.6119\n",
      "Epoch 5/10\n",
      " - 33s - loss: 1.5207 - accuracy: 0.4852 - val_loss: 1.1273 - val_accuracy: 0.6075\n",
      "Epoch 6/10\n",
      " - 33s - loss: 1.4925 - accuracy: 0.4960 - val_loss: 1.1025 - val_accuracy: 0.6081\n",
      "Epoch 7/10\n",
      " - 33s - loss: 1.4739 - accuracy: 0.5031 - val_loss: 1.0633 - val_accuracy: 0.6276\n",
      "Epoch 8/10\n",
      " - 33s - loss: 1.4594 - accuracy: 0.5085 - val_loss: 1.0672 - val_accuracy: 0.6341\n",
      "Epoch 9/10\n",
      " - 33s - loss: 1.4458 - accuracy: 0.5129 - val_loss: 1.0269 - val_accuracy: 0.6490\n",
      "Epoch 10/10\n",
      " - 34s - loss: 1.4339 - accuracy: 0.5170 - val_loss: 1.0150 - val_accuracy: 0.6443\n",
      "Train on 515040 samples, validate on 128760 samples\n",
      "Epoch 1/10\n",
      " - 35s - loss: 1.9459 - accuracy: 0.3392 - val_loss: 1.4470 - val_accuracy: 0.5238\n",
      "Epoch 2/10\n",
      " - 34s - loss: 1.6826 - accuracy: 0.4301 - val_loss: 1.2414 - val_accuracy: 0.5851\n",
      "Epoch 3/10\n",
      " - 32s - loss: 1.5794 - accuracy: 0.4638 - val_loss: 1.1483 - val_accuracy: 0.6141\n",
      "Epoch 4/10\n",
      " - 33s - loss: 1.5183 - accuracy: 0.4833 - val_loss: 1.0816 - val_accuracy: 0.6576\n",
      "Epoch 5/10\n",
      " - 33s - loss: 1.4789 - accuracy: 0.4973 - val_loss: 1.0492 - val_accuracy: 0.6513\n",
      "Epoch 6/10\n",
      " - 33s - loss: 1.4533 - accuracy: 0.5066 - val_loss: 1.0317 - val_accuracy: 0.6769\n",
      "Epoch 7/10\n",
      " - 32s - loss: 1.4338 - accuracy: 0.5125 - val_loss: 0.9949 - val_accuracy: 0.6737\n",
      "Epoch 8/10\n",
      " - 33s - loss: 1.4184 - accuracy: 0.5177 - val_loss: 0.9738 - val_accuracy: 0.6836\n",
      "Epoch 9/10\n",
      " - 33s - loss: 1.4138 - accuracy: 0.5189 - val_loss: 0.9613 - val_accuracy: 0.6970\n",
      "Epoch 10/10\n",
      " - 33s - loss: 1.4008 - accuracy: 0.5236 - val_loss: 0.9535 - val_accuracy: 0.7014\n",
      "Train on 515040 samples, validate on 128760 samples\n",
      "Epoch 1/10\n",
      " - 37s - loss: 1.9588 - accuracy: 0.3399 - val_loss: 1.4735 - val_accuracy: 0.4965\n",
      "Epoch 2/10\n",
      " - 34s - loss: 1.6979 - accuracy: 0.4298 - val_loss: 1.2747 - val_accuracy: 0.5543\n",
      "Epoch 3/10\n",
      " - 33s - loss: 1.6086 - accuracy: 0.4578 - val_loss: 1.1572 - val_accuracy: 0.6130\n",
      "Epoch 4/10\n",
      " - 34s - loss: 1.5604 - accuracy: 0.4734 - val_loss: 1.1111 - val_accuracy: 0.6217\n",
      "Epoch 5/10\n",
      " - 34s - loss: 1.5290 - accuracy: 0.4825 - val_loss: 1.0698 - val_accuracy: 0.6540\n",
      "Epoch 6/10\n",
      " - 34s - loss: 1.5004 - accuracy: 0.4922 - val_loss: 1.0413 - val_accuracy: 0.6528\n",
      "Epoch 7/10\n",
      " - 33s - loss: 1.4792 - accuracy: 0.4987 - val_loss: 1.0209 - val_accuracy: 0.6591\n",
      "Epoch 8/10\n",
      " - 34s - loss: 1.4604 - accuracy: 0.5051 - val_loss: 0.9921 - val_accuracy: 0.6752\n",
      "Epoch 9/10\n",
      " - 34s - loss: 1.4501 - accuracy: 0.5079 - val_loss: 0.9958 - val_accuracy: 0.6607\n",
      "Epoch 10/10\n",
      " - 33s - loss: 1.4383 - accuracy: 0.5117 - val_loss: 0.9836 - val_accuracy: 0.6636\n",
      "Train on 515040 samples, validate on 128760 samples\n",
      "Epoch 1/10\n",
      " - 34s - loss: 1.9650 - accuracy: 0.3311 - val_loss: 1.4971 - val_accuracy: 0.5097\n",
      "Epoch 2/10\n",
      " - 32s - loss: 1.7339 - accuracy: 0.4100 - val_loss: 1.3313 - val_accuracy: 0.5538\n",
      "Epoch 3/10\n",
      " - 32s - loss: 1.6412 - accuracy: 0.4405 - val_loss: 1.2202 - val_accuracy: 0.6042\n",
      "Epoch 4/10\n",
      " - 31s - loss: 1.5840 - accuracy: 0.4616 - val_loss: 1.1556 - val_accuracy: 0.6024\n",
      "Epoch 5/10\n",
      " - 32s - loss: 1.5499 - accuracy: 0.4733 - val_loss: 1.1233 - val_accuracy: 0.6278\n",
      "Epoch 6/10\n",
      " - 32s - loss: 1.5205 - accuracy: 0.4835 - val_loss: 1.0937 - val_accuracy: 0.6406\n",
      "Epoch 7/10\n",
      " - 36s - loss: 1.5017 - accuracy: 0.4925 - val_loss: 1.0736 - val_accuracy: 0.6486\n",
      "Epoch 8/10\n",
      " - 37s - loss: 1.4799 - accuracy: 0.5012 - val_loss: 1.0496 - val_accuracy: 0.6544\n",
      "Epoch 9/10\n",
      " - 36s - loss: 1.4631 - accuracy: 0.5073 - val_loss: 1.0232 - val_accuracy: 0.6594\n",
      "Epoch 10/10\n",
      " - 34s - loss: 1.4472 - accuracy: 0.5130 - val_loss: 1.0128 - val_accuracy: 0.6719\n",
      "Training accuracy:0.51659983\n",
      "Validation accuracy:0.6712270975112915\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation setup\n",
    "acc_train=[]\n",
    "acc_val=[]\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for train_index, val_index in kf.split(X):   \n",
    "    X_train=X[train_index]\n",
    "    Y_train=Y[train_index]\n",
    "    X_val=X[val_index]\n",
    "    Y_val=Y[val_index]\n",
    "    \n",
    "    #Transforming input variables into LSTM input format\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "    X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "    Y_train=Y_train\n",
    "    Y_val=Y_val\n",
    "    \n",
    "    #Creating model\n",
    "    model=create_network()\n",
    "    Hist=model.fit(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), verbose=2, class_weight=None)\n",
    "    \n",
    "    #Final epoch accuracies for training and validation dataset\n",
    "    acc_train.append(Hist.history[\"accuracy\"][-1])\n",
    "    acc_val.append(Hist.history[\"val_accuracy\"][-1])\n",
    "    \n",
    "print(\"Training accuracy:\" + str(np.mean(acc_train)))\n",
    "print(\"Validation accuracy:\" + str(np.mean(acc_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset while using test_train split for final prediction\n",
    "\n",
    "#Transforming input variables into LSTM input format\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20 , random_state=4)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "Y_train=Y_train\n",
    "Y_val=Y_val\n",
    "\n",
    "X_test=temporal_df_test.iloc[:, 0:(num_years*len(features))]\n",
    "X_test = X_test.values.reshape(X_test.shape[0], num_years, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 211198 samples, validate on 52800 samples\n",
      "Epoch 1/40\n",
      " - 15s - loss: 1.8193 - accuracy: 0.3750 - val_loss: 1.3498 - val_accuracy: 0.5210\n",
      "Epoch 2/40\n",
      " - 14s - loss: 1.5543 - accuracy: 0.4543 - val_loss: 1.2068 - val_accuracy: 0.5698\n",
      "Epoch 3/40\n",
      " - 14s - loss: 1.4727 - accuracy: 0.4833 - val_loss: 1.1086 - val_accuracy: 0.6256\n",
      "Epoch 4/40\n",
      " - 14s - loss: 1.4148 - accuracy: 0.5055 - val_loss: 1.0304 - val_accuracy: 0.6469\n",
      "Epoch 5/40\n",
      " - 14s - loss: 1.3697 - accuracy: 0.5249 - val_loss: 0.9726 - val_accuracy: 0.6664\n",
      "Epoch 6/40\n",
      " - 13s - loss: 1.3383 - accuracy: 0.5371 - val_loss: 0.9373 - val_accuracy: 0.6638\n",
      "Epoch 7/40\n",
      " - 13s - loss: 1.3074 - accuracy: 0.5490 - val_loss: 0.9042 - val_accuracy: 0.6936\n",
      "Epoch 8/40\n",
      " - 14s - loss: 1.2893 - accuracy: 0.5556 - val_loss: 0.8904 - val_accuracy: 0.6881\n",
      "Epoch 9/40\n",
      " - 13s - loss: 1.2716 - accuracy: 0.5601 - val_loss: 0.8640 - val_accuracy: 0.6991\n",
      "Epoch 10/40\n",
      " - 13s - loss: 1.2557 - accuracy: 0.5662 - val_loss: 0.8488 - val_accuracy: 0.7148\n",
      "Epoch 11/40\n",
      " - 14s - loss: 1.2441 - accuracy: 0.5701 - val_loss: 0.8425 - val_accuracy: 0.7041\n",
      "Epoch 12/40\n",
      " - 14s - loss: 1.2324 - accuracy: 0.5716 - val_loss: 0.8192 - val_accuracy: 0.7233\n",
      "Epoch 13/40\n",
      " - 14s - loss: 1.2219 - accuracy: 0.5759 - val_loss: 0.8143 - val_accuracy: 0.7243\n",
      "Epoch 14/40\n",
      " - 14s - loss: 1.2145 - accuracy: 0.5769 - val_loss: 0.8112 - val_accuracy: 0.7138\n",
      "Epoch 15/40\n",
      " - 14s - loss: 1.2031 - accuracy: 0.5814 - val_loss: 0.7997 - val_accuracy: 0.7021\n",
      "Epoch 16/40\n",
      " - 13s - loss: 1.1945 - accuracy: 0.5823 - val_loss: 0.7792 - val_accuracy: 0.7256\n",
      "Epoch 17/40\n",
      " - 14s - loss: 1.1894 - accuracy: 0.5849 - val_loss: 0.7851 - val_accuracy: 0.7179\n",
      "Epoch 18/40\n",
      " - 15s - loss: 1.1832 - accuracy: 0.5863 - val_loss: 0.7778 - val_accuracy: 0.7192\n",
      "Epoch 19/40\n",
      " - 14s - loss: 1.1743 - accuracy: 0.5895 - val_loss: 0.7751 - val_accuracy: 0.7277\n",
      "Epoch 20/40\n",
      " - 15s - loss: 1.1738 - accuracy: 0.5908 - val_loss: 0.7725 - val_accuracy: 0.7211\n",
      "Epoch 21/40\n",
      " - 15s - loss: 1.1687 - accuracy: 0.5904 - val_loss: 0.7672 - val_accuracy: 0.7293\n",
      "Epoch 22/40\n",
      " - 15s - loss: 1.1611 - accuracy: 0.5936 - val_loss: 0.7689 - val_accuracy: 0.7158\n",
      "Epoch 23/40\n",
      " - 15s - loss: 1.1533 - accuracy: 0.5964 - val_loss: 0.7583 - val_accuracy: 0.7226\n",
      "Epoch 24/40\n",
      " - 17s - loss: 1.1526 - accuracy: 0.5960 - val_loss: 0.7468 - val_accuracy: 0.7356\n",
      "Epoch 25/40\n",
      " - 15s - loss: 1.1452 - accuracy: 0.5979 - val_loss: 0.7515 - val_accuracy: 0.7233\n",
      "Epoch 26/40\n",
      " - 15s - loss: 1.1368 - accuracy: 0.6011 - val_loss: 0.7494 - val_accuracy: 0.7329\n",
      "Epoch 27/40\n",
      " - 15s - loss: 1.1368 - accuracy: 0.6006 - val_loss: 0.7409 - val_accuracy: 0.7403\n",
      "Epoch 28/40\n",
      " - 15s - loss: 1.1322 - accuracy: 0.6028 - val_loss: 0.7486 - val_accuracy: 0.7272\n",
      "Epoch 29/40\n",
      " - 15s - loss: 1.1224 - accuracy: 0.6058 - val_loss: 0.7310 - val_accuracy: 0.7305\n",
      "Epoch 30/40\n",
      " - 15s - loss: 1.1241 - accuracy: 0.6055 - val_loss: 0.7304 - val_accuracy: 0.7389\n",
      "Epoch 31/40\n",
      " - 14s - loss: 1.1210 - accuracy: 0.6077 - val_loss: 0.7310 - val_accuracy: 0.7366\n",
      "Epoch 32/40\n",
      " - 15s - loss: 1.1124 - accuracy: 0.6098 - val_loss: 0.7307 - val_accuracy: 0.7303\n",
      "Epoch 33/40\n",
      " - 14s - loss: 1.1104 - accuracy: 0.6098 - val_loss: 0.7256 - val_accuracy: 0.7448\n",
      "Epoch 34/40\n",
      " - 15s - loss: 1.1100 - accuracy: 0.6116 - val_loss: 0.7239 - val_accuracy: 0.7449\n",
      "Epoch 35/40\n",
      " - 14s - loss: 1.1070 - accuracy: 0.6117 - val_loss: 0.7173 - val_accuracy: 0.7532\n",
      "Epoch 36/40\n",
      " - 15s - loss: 1.1047 - accuracy: 0.6121 - val_loss: 0.7313 - val_accuracy: 0.7380\n",
      "Epoch 37/40\n",
      " - 14s - loss: 1.1026 - accuracy: 0.6133 - val_loss: 0.7158 - val_accuracy: 0.7563\n",
      "Epoch 38/40\n",
      " - 15s - loss: 1.0984 - accuracy: 0.6153 - val_loss: 0.7174 - val_accuracy: 0.7541\n",
      "Epoch 39/40\n",
      " - 15s - loss: 1.0990 - accuracy: 0.6141 - val_loss: 0.7188 - val_accuracy: 0.7452\n",
      "Epoch 40/40\n",
      " - 14s - loss: 1.0954 - accuracy: 0.6148 - val_loss: 0.7106 - val_accuracy: 0.7537\n"
     ]
    }
   ],
   "source": [
    "Hist=model.fit(X_train, Y_train, nb_epoch=40, validation_data=(X_val, Y_val), verbose=2, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(Hist.history['accuracy'])\n",
    "plt.plot(Hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(Hist.history['loss'])\n",
    "plt.plot(Hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using unbalanced data\n",
    "temporal_df = temporal_df.sample(frac = 1) #Shuffling the data\n",
    "X_pre = temporal_df.iloc[:, 0:(num_years*len(features))]\n",
    "Y_pre = temporal_df.iloc[:, (num_years*len(features)):]\n",
    "X=X_pre.values\n",
    "Y=Y_pre.values\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_years, len(features))\n",
    "X_val = X_val.reshape(X_val.shape[0], num_years, len(features))\n",
    "Y_train=Y_train\n",
    "Y_val=Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting value for train, val, and test datasets\n",
    "pred_train=model.predict(X_train)\n",
    "pred_val=model.predict(X_val)\n",
    "#pred_test=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting probabilities to class labels\n",
    "pred_train_class=np.argmax(pred_train, axis=1)+1\n",
    "pred_train_class=list(map(lambda x: str(x), pred_train_class))\n",
    "pred_val_class=np.argmax(pred_val, axis=1)+1\n",
    "pred_val_class=list(map(lambda x: str(x), pred_val_class))\n",
    "#pred_test_class=np.argmax(pred_test, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train_class=np.argmax(Y_train, axis=1)+1\n",
    "true_train_class=list(map(lambda x: str(x), true_train_class))\n",
    "true_val_class=np.argmax(Y_val, axis=1)+1\n",
    "true_val_class=list(map(lambda x: str(x), true_val_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i) for i in range(1,16)]\n",
    "cm_train = confusion_matrix(true_train_class, pred_train_class , labels)\n",
    "#cm_train=cm_train.astype('float') / cm_train.sum(axis=1)[:, np.newaxis] #For normalizing\n",
    "cm_val = confusion_matrix(true_val_class, pred_val_class , labels)\n",
    "#cm_val=cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis] #For normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1     2     3     4     5     6     7     8     9    10    11    12    13    14    15 \n",
      "        1 10838.0 1375.0 182.0 444.0 679.0 703.0 479.0  35.0 148.0  45.0  34.0  74.0  22.0  28.0   0.0 \n",
      "        2 937.0 267.0  68.0 134.0 155.0 144.0 166.0  16.0  45.0  24.0  20.0  38.0   5.0  10.0   0.0 \n",
      "        3  10.0  12.0  13.0  12.0  22.0  18.0  17.0   3.0   7.0   2.0   3.0  10.0   4.0   0.0   0.0 \n",
      "        4   0.0   5.0   3.0  12.0   7.0   2.0   4.0   2.0   4.0   0.0   2.0   2.0   0.0   0.0   0.0 \n",
      "        5   0.0   1.0   0.0   2.0  13.0   1.0   1.0   0.0   0.0   2.0   1.0   1.0   1.0   0.0   0.0 \n",
      "        6   0.0   1.0   0.0   0.0   1.0  12.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        7   0.0   0.0   0.0   0.0   0.0   0.0  10.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        8   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        9   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       10   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       11   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0   0.0   0.0   0.0 \n",
      "       12   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   7.0   0.0   0.0   0.0 \n",
      "       13   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0 \n",
      "       14   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       15   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(cm_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1     2     3     4     5     6     7     8     9    10    11    12    13    14    15 \n",
      "        1 2644.0 357.0  40.0 122.0 210.0 180.0 130.0   6.0  36.0  13.0   6.0  16.0   2.0   9.0   0.0 \n",
      "        2 232.0  64.0  12.0  31.0  35.0  45.0  44.0   5.0  15.0   4.0   6.0   7.0   3.0   4.0   0.0 \n",
      "        3   2.0   5.0   7.0   5.0   3.0   6.0   2.0   1.0   3.0   1.0   1.0   1.0   0.0   0.0   0.0 \n",
      "        4   1.0   2.0   0.0   5.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   2.0   0.0   0.0   0.0 \n",
      "        5   0.0   0.0   1.0   0.0   3.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        6   0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        7   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        8   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "        9   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       10   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n",
      "       11   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0 \n",
      "       12   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0 \n",
      "       13   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0 \n",
      "       14   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0 \n",
      "       15   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(cm_val, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.70      0.80      3771\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.07      1.00      0.13         1\n",
      "          12       0.07      1.00      0.13         2\n",
      "          13       0.17      1.00      0.29         1\n",
      "          14       0.07      1.00      0.13         1\n",
      "           2       0.15      0.13      0.14       507\n",
      "           3       0.12      0.19      0.14        37\n",
      "           4       0.03      0.45      0.06        11\n",
      "           5       0.01      0.60      0.02         5\n",
      "           6       0.01      1.00      0.03         3\n",
      "           7       0.02      1.00      0.03         3\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.63      4342\n",
      "   macro avg       0.12      0.58      0.14      4342\n",
      "weighted avg       0.82      0.63      0.71      4342\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Evaluation metrics for valdation dataset\n",
    "print(metrics.classification_report(true_val_class, pred_val_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Implementation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization(input_shape=(num_years, len(features))))\n",
    "    network.add(Dense(4, activation=\"tanh\"))\n",
    "    network.add(LSTM(15, dropout = 0.2, recurrent_dropout = 0.2, activation=\"tanh\"))\n",
    "    network.add(Dense(1, activation=\"tanh\"))\n",
    "    network.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12432 samples, validate on 12432 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.7554 - accuracy: 0.8436 - val_loss: 0.4844 - val_accuracy: 0.8439\n",
      "Train on 12432 samples, validate on 12432 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.7612 - accuracy: 0.8254 - val_loss: 0.4337 - val_accuracy: 0.8642\n",
      "Training accuracy:0.8344997\n",
      "Validation accuracy:0.8540459871292114\n"
     ]
    }
   ],
   "source": [
    "#Cross-validation setup\n",
    "acc_train=[]\n",
    "acc_val=[]\n",
    "kf = KFold(n_splits=2)\n",
    "for train_index, val_index in kf.split(temporal_df):   \n",
    "    X_train=temporal_df.iloc[train_index,0:(num_years*len(features))]\n",
    "    Y_train=temporal_df.iloc[train_index,(num_years*len(features)):]\n",
    "    X_val=temporal_df.iloc[val_index,0:(num_years*len(features))]\n",
    "    Y_val=temporal_df.iloc[val_index,(num_years*len(features)):]\n",
    "    \n",
    "    #Transforming input variables into LSTM input format\n",
    "    X_train = X_train.values.reshape(X_train.shape[0], num_years, len(features))\n",
    "    X_val = X_val.values.reshape(X_val.shape[0], num_years, len(features))\n",
    "    Y_train=Y_train.values\n",
    "    Y_val=Y_val.values\n",
    "    \n",
    "    #Creating model\n",
    "    model=create_network()\n",
    "    Hist=model.fit(X_train, Y_train, epochs=1, validation_data=(X_val, Y_val), verbose=2)\n",
    "    \n",
    "    #Final epoch accuracies for training and validation dataset\n",
    "    acc_train.append(Hist.history[\"accuracy\"][-1])\n",
    "    acc_val.append(Hist.history[\"val_accuracy\"][-1])\n",
    "    \n",
    "print(\"Training accuracy:\" + str(np.mean(acc_train)))\n",
    "print(\"Validation accuracy:\" + str(np.mean(acc_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.82e-02, 5.04e-01, 7.47e+00, 2.81e+01, 6.63e+01, 8.72e+01,\n",
       "       2.37e+02, 2.37e+02, 8.29e+02, 4.14e+02, 5.53e+02, 1.51e+02,\n",
       "       2.76e+02, 5.53e+02, 8.29e+02])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 2s - loss: 1.3761 - accuracy: 0.8402\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.5475 - accuracy: 0.8655\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.4853 - accuracy: 0.8655\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.4663 - accuracy: 0.8655\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.4594 - accuracy: 0.8655\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.4565 - accuracy: 0.8655\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.4539 - accuracy: 0.8655\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.4541 - accuracy: 0.8651\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.4518 - accuracy: 0.8644\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.4490 - accuracy: 0.8652\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.4493 - accuracy: 0.8652\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.4468 - accuracy: 0.8648\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.4440 - accuracy: 0.8658\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.4433 - accuracy: 0.8657\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.4426 - accuracy: 0.8649\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.4406 - accuracy: 0.8669\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.4400 - accuracy: 0.8659\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.4394 - accuracy: 0.8652\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.4374 - accuracy: 0.8659\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.4366 - accuracy: 0.8665\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.4388 - accuracy: 0.8644\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.4358 - accuracy: 0.8659\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.4341 - accuracy: 0.8658\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.4333 - accuracy: 0.8657\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.4346 - accuracy: 0.8653\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.4331 - accuracy: 0.8652\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.4317 - accuracy: 0.8652\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.4319 - accuracy: 0.8665\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.4310 - accuracy: 0.8650\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.4302 - accuracy: 0.8650\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.4294 - accuracy: 0.8652\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.4305 - accuracy: 0.8652\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.4292 - accuracy: 0.8647\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.4285 - accuracy: 0.8657\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8655\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.4293 - accuracy: 0.8648\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8645\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.4272 - accuracy: 0.8656\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8652\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.4283 - accuracy: 0.8650\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.4262 - accuracy: 0.8660\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.4279 - accuracy: 0.8643\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.4278 - accuracy: 0.8652\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.4272 - accuracy: 0.8651\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.4275 - accuracy: 0.8650\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.4273 - accuracy: 0.8657\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8647\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.4268 - accuracy: 0.8644\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8646\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.4254 - accuracy: 0.8655\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.4271 - accuracy: 0.8636\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.4262 - accuracy: 0.8652\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.4266 - accuracy: 0.8653\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.4267 - accuracy: 0.8651\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.4265 - accuracy: 0.8645\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8653\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.4261 - accuracy: 0.8650\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8651\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8649\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.4263 - accuracy: 0.8653\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8655\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.4264 - accuracy: 0.8647\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.4260 - accuracy: 0.8648\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8650\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8657\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.4266 - accuracy: 0.8646\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8648\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8656\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8649\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8654\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8648\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.4244 - accuracy: 0.8654\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.4252 - accuracy: 0.8658\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.4258 - accuracy: 0.8649\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8636\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8648\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8655\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.4255 - accuracy: 0.8652\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8650\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8641\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.4247 - accuracy: 0.8645\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8639\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.4256 - accuracy: 0.8641\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8654\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.4257 - accuracy: 0.8658\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8645\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8641\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.4260 - accuracy: 0.8646\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.4256 - accuracy: 0.8650\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.4256 - accuracy: 0.8646\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8653\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8650\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8653\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8653\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.4244 - accuracy: 0.8654\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8656\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.4248 - accuracy: 0.8651\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.4242 - accuracy: 0.8648\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.4247 - accuracy: 0.8652\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8652\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.4244 - accuracy: 0.8639\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8659\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.4243 - accuracy: 0.8653\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8647\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8656\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8649\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.4252 - accuracy: 0.8651\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8645\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8655\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.4250 - accuracy: 0.8639\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8650\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8651\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8648\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8638\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.4238 - accuracy: 0.8645\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.4253 - accuracy: 0.8648\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.4259 - accuracy: 0.8647\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.4243 - accuracy: 0.8650\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8643\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8645\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8652\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.4246 - accuracy: 0.8652\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.4245 - accuracy: 0.8648\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8655\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.4248 - accuracy: 0.8648\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.4249 - accuracy: 0.8648\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.4240 - accuracy: 0.8654\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-689ecda38a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_network, epochs=200, batch_size=64, verbose=2)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# network.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = Sequential()\n",
    "    network.add(BatchNormalization())\n",
    "    network.add(Dense(3000, activation=\"relu\", input_shape=(39782,)))\n",
    "    network.add(Dense(1500, activation=\"relu\"))\n",
    "    network.add(Dense(300, activation=\"relu\"))\n",
    "    network.add(Dense(15, activation=\"softmax\"))\n",
    "\n",
    "    network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 30s - loss: 0.4627 - accuracy: 0.8632\n",
      "Epoch 2/8\n",
      " - 30s - loss: 0.4319 - accuracy: 0.8668\n",
      "Epoch 3/8\n",
      " - 30s - loss: 0.4278 - accuracy: 0.8664\n",
      "Epoch 4/8\n",
      " - 30s - loss: 0.4261 - accuracy: 0.8661\n",
      "Epoch 5/8\n",
      " - 30s - loss: 0.4256 - accuracy: 0.8661\n",
      "Epoch 6/8\n",
      " - 31s - loss: 0.4247 - accuracy: 0.8668\n",
      "Epoch 7/8\n",
      " - 32s - loss: 0.4238 - accuracy: 0.8667\n",
      "Epoch 8/8\n",
      " - 30s - loss: 0.4224 - accuracy: 0.8676\n",
      "Epoch 1/8\n",
      " - 33s - loss: 0.4635 - accuracy: 0.8644\n",
      "Epoch 2/8\n",
      " - 31s - loss: 0.4290 - accuracy: 0.8678\n",
      "Epoch 3/8\n",
      " - 30s - loss: 0.4253 - accuracy: 0.8676\n",
      "Epoch 4/8\n",
      " - 31s - loss: 0.4237 - accuracy: 0.8675\n",
      "Epoch 5/8\n",
      " - 31s - loss: 0.4218 - accuracy: 0.8678\n",
      "Epoch 6/8\n",
      " - 30s - loss: 0.4206 - accuracy: 0.8689\n",
      "Epoch 7/8\n",
      " - 30s - loss: 0.4200 - accuracy: 0.8682\n",
      "Epoch 8/8\n",
      " - 30s - loss: 0.4201 - accuracy: 0.8687\n",
      "Epoch 1/8\n",
      " - 31s - loss: 0.4646 - accuracy: 0.8620\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4312 - accuracy: 0.8659\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4283 - accuracy: 0.8667\n",
      "Epoch 4/8\n",
      " - 30s - loss: 0.4257 - accuracy: 0.8667\n",
      "Epoch 5/8\n",
      " - 31s - loss: 0.4258 - accuracy: 0.8668\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.4247 - accuracy: 0.8663\n",
      "Epoch 7/8\n",
      " - 29s - loss: 0.4244 - accuracy: 0.8661\n",
      "Epoch 8/8\n",
      " - 29s - loss: 0.4230 - accuracy: 0.8667\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4605 - accuracy: 0.8643\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4293 - accuracy: 0.8672\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4269 - accuracy: 0.8679\n",
      "Epoch 4/8\n",
      " - 29s - loss: 0.4247 - accuracy: 0.8676\n",
      "Epoch 5/8\n",
      " - 29s - loss: 0.4240 - accuracy: 0.8677\n",
      "Epoch 6/8\n",
      " - 29s - loss: 0.4228 - accuracy: 0.8671\n",
      "Epoch 7/8\n",
      " - 28s - loss: 0.4222 - accuracy: 0.8671\n",
      "Epoch 8/8\n",
      " - 29s - loss: 0.4221 - accuracy: 0.8683\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4625 - accuracy: 0.8633\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4319 - accuracy: 0.8665\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4278 - accuracy: 0.8660\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.4252 - accuracy: 0.8673\n",
      "Epoch 5/8\n",
      " - 29s - loss: 0.4248 - accuracy: 0.8668\n",
      "Epoch 6/8\n",
      " - 29s - loss: 0.4248 - accuracy: 0.8667\n",
      "Epoch 7/8\n",
      " - 28s - loss: 0.4235 - accuracy: 0.8667\n",
      "Epoch 8/8\n",
      " - 28s - loss: 0.4229 - accuracy: 0.8663\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4600 - accuracy: 0.8628\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4318 - accuracy: 0.8662\n",
      "Epoch 3/8\n",
      " - 28s - loss: 0.4271 - accuracy: 0.8664\n",
      "Epoch 4/8\n",
      " - 29s - loss: 0.4273 - accuracy: 0.8663\n",
      "Epoch 5/8\n",
      " - 29s - loss: 0.4250 - accuracy: 0.8662\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.4244 - accuracy: 0.8666\n",
      "Epoch 7/8\n",
      " - 28s - loss: 0.4237 - accuracy: 0.8667\n",
      "Epoch 8/8\n",
      " - 28s - loss: 0.4232 - accuracy: 0.8669\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.4553 - accuracy: 0.8661\n",
      "Epoch 2/8\n",
      " - 29s - loss: 0.4249 - accuracy: 0.8686\n",
      "Epoch 3/8\n",
      " - 29s - loss: 0.4227 - accuracy: 0.8681\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.4215 - accuracy: 0.8689\n",
      "Epoch 5/8\n",
      " - 28s - loss: 0.4203 - accuracy: 0.8680\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.4186 - accuracy: 0.8686\n",
      "Epoch 7/8\n",
      " - 29s - loss: 0.4191 - accuracy: 0.8688\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4165 - accuracy: 0.8695\n",
      "Epoch 1/8\n",
      " - 42s - loss: 0.4605 - accuracy: 0.8626\n",
      "Epoch 2/8\n",
      " - 37s - loss: 0.4303 - accuracy: 0.8664\n",
      "Epoch 3/8\n",
      " - 37s - loss: 0.4270 - accuracy: 0.8668\n",
      "Epoch 4/8\n",
      " - 36s - loss: 0.4251 - accuracy: 0.8668\n",
      "Epoch 5/8\n",
      " - 37s - loss: 0.4226 - accuracy: 0.8676\n",
      "Epoch 6/8\n",
      " - 37s - loss: 0.4229 - accuracy: 0.8672\n",
      "Epoch 7/8\n",
      " - 38s - loss: 0.4209 - accuracy: 0.8675\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4200 - accuracy: 0.8664\n",
      "Epoch 1/8\n",
      " - 39s - loss: 0.4612 - accuracy: 0.8648\n",
      "Epoch 2/8\n",
      " - 37s - loss: 0.4321 - accuracy: 0.8671\n",
      "Epoch 3/8\n",
      " - 37s - loss: 0.4256 - accuracy: 0.8663\n",
      "Epoch 4/8\n",
      " - 37s - loss: 0.4250 - accuracy: 0.8673\n",
      "Epoch 5/8\n",
      " - 37s - loss: 0.4249 - accuracy: 0.8674\n",
      "Epoch 6/8\n",
      " - 37s - loss: 0.4230 - accuracy: 0.8676\n",
      "Epoch 7/8\n",
      " - 37s - loss: 0.4214 - accuracy: 0.8672\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4227 - accuracy: 0.8668\n",
      "Epoch 1/8\n",
      " - 39s - loss: 0.4653 - accuracy: 0.8635\n",
      "Epoch 2/8\n",
      " - 37s - loss: 0.4296 - accuracy: 0.8666\n",
      "Epoch 3/8\n",
      " - 37s - loss: 0.4269 - accuracy: 0.8671\n",
      "Epoch 4/8\n",
      " - 37s - loss: 0.4245 - accuracy: 0.8669\n",
      "Epoch 5/8\n",
      " - 37s - loss: 0.4248 - accuracy: 0.8678\n",
      "Epoch 6/8\n",
      " - 37s - loss: 0.4240 - accuracy: 0.8671\n",
      "Epoch 7/8\n",
      " - 37s - loss: 0.4222 - accuracy: 0.8676\n",
      "Epoch 8/8\n",
      " - 37s - loss: 0.4216 - accuracy: 0.8677\n",
      "Baseline: 86.56% (0.69%)\n"
     ]
    }
   ],
   "source": [
    "X = temporal_df.iloc[:, 0:4].values\n",
    "Y = temporal_df.iloc[:, 4:].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_network, epochs=8, batch_size=64, verbose=2)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train, Y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.56% (0.686%)\n"
     ]
    }
   ],
   "source": [
    "# This is a reasonable estimation of the performance of the model on unseen data.\n",
    "\n",
    "print('Accuracy: %.2f%% (%.3f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39782 samples, validate on 9946 samples\n",
      "Epoch 1/8\n",
      " - 74s - loss: 0.4495 - accuracy: 0.8642 - val_loss: 0.4511 - val_accuracy: 0.8674\n",
      "Epoch 2/8\n",
      " - 69s - loss: 0.4313 - accuracy: 0.8647 - val_loss: 0.4353 - val_accuracy: 0.8682\n",
      "Epoch 3/8\n",
      " - 69s - loss: 0.4274 - accuracy: 0.8667 - val_loss: 0.4306 - val_accuracy: 0.8678\n",
      "Epoch 4/8\n",
      " - 72s - loss: 0.4258 - accuracy: 0.8660 - val_loss: 0.4265 - val_accuracy: 0.8678\n",
      "Epoch 5/8\n",
      " - 70s - loss: 0.4262 - accuracy: 0.8662 - val_loss: 0.4274 - val_accuracy: 0.8688\n",
      "Epoch 6/8\n",
      " - 71s - loss: 0.4253 - accuracy: 0.8664 - val_loss: 0.4248 - val_accuracy: 0.8680\n",
      "Epoch 7/8\n",
      " - 71s - loss: 0.4231 - accuracy: 0.8665 - val_loss: 0.4242 - val_accuracy: 0.8680\n",
      "Epoch 8/8\n",
      " - 70s - loss: 0.4229 - accuracy: 0.8670 - val_loss: 0.4302 - val_accuracy: 0.8668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2157ea7d8d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = create_network()\n",
    "network.fit(X_train, Y_train, epochs=8, validation_data=(X_test, Y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9946/9946 [==============================] - 2s 237us/step\n"
     ]
    }
   ],
   "source": [
    "results2 = network.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.68% \n",
      "Loss: 0.430\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f%% \\nLoss: %.3f' % (results2[1]*100, results2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = network.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = pd.DataFrame(Y_pred_test)\n",
    "Y_pred_test = Y_pred_test.T\n",
    "for i in Y_pred_test.columns.tolist():\n",
    "    Y_pred_test[i] = np.where(Y_pred_test[i] == max(Y_pred_test[i]), 1, 0)\n",
    "\n",
    "Y_pred_test = Y_pred_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
       "0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "5   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "6   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "7   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "8   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "9   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
       "0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "2   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "3   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "4   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "5   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "6   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "7   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "8   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "9   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = pd.DataFrame(Y_test)\n",
    "Y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
